{"meta":{"title":"雪山上的蒲公英","subtitle":"JinFeng's Blog","description":"Stay hungry, Stay foolish.","author":"Zang JinFeng","url":"https://xssdpgy.github.io","root":"/"},"pages":[{"title":"关于","date":"2022-04-07T06:04:21.000Z","updated":"2022-09-11T15:43:16.282Z","comments":false,"path":"about/index.html","permalink":"https://xssdpgy.github.io/about/index.html","excerpt":"","text":"程序员一枚，专向互金工程领域。"},{"title":"分类","date":"2022-04-06T15:33:39.000Z","updated":"2022-09-11T15:43:16.282Z","comments":false,"path":"categories/index.html","permalink":"https://xssdpgy.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2022-04-06T15:31:49.000Z","updated":"2022-09-11T15:43:16.283Z","comments":false,"path":"tags/index.html","permalink":"https://xssdpgy.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"SpringBoot异步方法优化处理提高响应速度","slug":"SpringBoot异步方法优化处理提高响应速度","date":"2022-04-21T02:48:24.000Z","updated":"2022-09-11T15:43:16.281Z","comments":true,"path":"2022/04/21/SpringBoot异步方法优化处理提高响应速度/","link":"","permalink":"https://xssdpgy.github.io/2022/04/21/SpringBoot%E5%BC%82%E6%AD%A5%E6%96%B9%E6%B3%95%E4%BC%98%E5%8C%96%E5%A4%84%E7%90%86%E6%8F%90%E9%AB%98%E5%93%8D%E5%BA%94%E9%80%9F%E5%BA%A6/","excerpt":"1.前言日常开发中，对于串行化的任务适当解耦耗时操作和业务逻辑，在保证结果准确性的前提下，使用异步方法适当进行并行化改造，可以提高接口响应速度，提升使用体验。 如下抽象的串行化工作流程： 业务查询，首先登记记录record[cost 3s]，之后依次执行searchA[cost 1s]、searchB[cost 2s]、searchC[cost 2s]分别得到变量a、b、c，返回结果fx(a,b,c)[计算耗时可忽略不记]。代码如下：","text":"1.前言日常开发中，对于串行化的任务适当解耦耗时操作和业务逻辑，在保证结果准确性的前提下，使用异步方法适当进行并行化改造，可以提高接口响应速度，提升使用体验。 如下抽象的串行化工作流程： 业务查询，首先登记记录record[cost 3s]，之后依次执行searchA[cost 1s]、searchB[cost 2s]、searchC[cost 2s]分别得到变量a、b、c，返回结果fx(a,b,c)[计算耗时可忽略不记]。代码如下： 123456789101112131415161718192021222324252627282930import com.zang.async.service.AsyncCaseService;import lombok.extern.slf4j.Slf4j;import org.springframework.web.bind.annotation.PostMapping;import org.springframework.web.bind.annotation.RestController;import javax.annotation.Resource;import java.time.Duration;import java.time.Instant;@Slf4j@RestControllerpublic class AsyncCaseController &#123; @Resource private AsyncCaseService asyncCaseService; @PostMapping(&quot;/search/sync-test&quot;) public int syncSearch()&#123; log.info(&quot;========test start=========&quot;); Instant start = Instant.now(); asyncCaseService.record(); int a = asyncCaseService.searchA(); int b = asyncCaseService.searchB(); int c = asyncCaseService.searchC(); int result = a+b+c; Instant end = Instant.now(); log.info(&quot;========test end=========cost time is &#123;&#125; seconds&quot;, Duration.between(start,end).getSeconds()); return result; &#125; ··· 123456789101112131415161718import org.springframework.stereotype.Service;@Servicepublic class AsyncCaseServiceImpl implements AsyncCaseService&#123; @Override public int searchA() &#123; try &#123; Thread.sleep(1000);//模拟业务处理耗时 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return 1; &#125; @Override public int searchB() &#123; //其他方法类似 执行结果： 122022-04-21 13:32:47.739 INFO 22764 --- [nio-8089-exec-2] com.zang.async.web.AsyncCaseController : ========test start=========2022-04-21 13:32:55.762 INFO 22764 --- [nio-8089-exec-2] com.zang.async.web.AsyncCaseController : ========test end=========cost time is 8 seconds 经过分析，可以看到三个查询方法可以并行执行，等待都产生结果执行fx(a,b,c)，record方法执行的顺序和完成度不影响结果的返回，可以使用异步任务执行。改造逻辑抽象如下： 之后就代码实现展开阐述。 2.SpringBoot中的异步方法支持SpringBoot已经提供了异步方法支持注解，因此不需要我们自己去创建维护线程或者线程池来异步的执行方法。 主要依靠两个注解： 12@EnableAsync // 使用异步方法时需要提前开启(在启动类上或配置类上)@Async // 被async注解修饰的方法由SpringBoot默认线程池(SimpleAsyncTaskExecutor)执行 2.1 获取(有返回值)异步方法的返回值对于有返回值的异步方法，可使用java.util.concurrent.Future类及其子类来接收异步方法返回值。 1234567891011121314151617181920import org.springframework.scheduling.annotation.Async;import org.springframework.scheduling.annotation.AsyncResult;import org.springframework.stereotype.Service;import java.util.concurrent.Future;@Servicepublic class AsyncCaseServiceImpl implements AsyncCaseService&#123; @Async @Override public Future&lt;Integer&gt; searchA() &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return new AsyncResult&lt;&gt;(1); &#125; //略 无返回值异步方法的异常捕获见3.3。 2.2 异步任务并行控制接上节，在对Service中有返回值的方法进行异步改造的同时，业务处理侧需要添加并行控制，使并行的异步都返回结果才进行下一步操作： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455import com.zang.async.service.AsyncCaseService;import lombok.extern.slf4j.Slf4j;import org.springframework.web.bind.annotation.PostMapping;import org.springframework.web.bind.annotation.RestController;import javax.annotation.Resource;import java.time.Duration;import java.time.Instant;import java.util.concurrent.Future;@Slf4j@RestControllerpublic class AsyncCaseController &#123; @Resource private AsyncCaseService asyncCaseService; @PostMapping(&quot;/search/async-test&quot;) public int asyncSearch() &#123; log.info(&quot;========test start=========&quot;); Instant start = Instant.now(); asyncCaseService.record(); Future&lt;Integer&gt; searchAFuture = asyncCaseService.searchA(); Future&lt;Integer&gt; searchBFuture = asyncCaseService.searchB(); Future&lt;Integer&gt; searchCFuture = asyncCaseService.searchC(); while (true) &#123; if (searchAFuture.isDone() &amp;&amp; searchBFuture.isDone() &amp;&amp; searchCFuture.isDone()) &#123; break; &#125; if (searchAFuture.isCancelled() || searchBFuture.isCancelled() || searchCFuture.isCancelled()) &#123; log.info(&quot;async work has cancelled , break&quot;); break; &#125; try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; int a = 0, b = 0, c = 0; try &#123; a = searchAFuture.get(); b = searchBFuture.get(); c = searchCFuture.get(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; int result = a + b + c; Instant end = Instant.now(); log.info(&quot;========test end=========cost time is &#123;&#125; seconds&quot;, Duration.between(start, end).getSeconds()); return result; &#125;&#125; 结果： 122022-04-21 14:23:35.486 INFO 19912 --- [nio-8089-exec-4] com.zang.async.web.AsyncCaseController : ========test start=========2022-04-21 14:23:37.516 INFO 19912 --- [nio-8089-exec-4] com.zang.async.web.AsyncCaseController : ========test end=========cost time is 2 seconds 3.自定义线程池执行异步方法@Async使用了线程池org.springframework.core.task.SimpleAsyncTaskExecutor来执行我们的异步方法，实际开发中我们也可以自定义自己的线程池，便于对线程池进行合理配置。 3.1 自定义线程池12345678910111213141516171819202122232425262728import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.scheduling.annotation.EnableAsync;import org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;import java.util.concurrent.Executor;import java.util.concurrent.ThreadPoolExecutor;@EnableAsync@Configurationpublic class AsyncThreadPoolConfigure &#123; @Bean(&quot;asyncThreadPoolTaskExecutor&quot;) public Executor asyncThreadPoolTaskExecutor() &#123; ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(4); executor.setMaxPoolSize(4); executor.setQueueCapacity(10); executor.setKeepAliveSeconds(60); executor.setThreadNamePrefix(&quot;async-task-executor&quot;); executor.setThreadGroupName(&quot;async-task-executor-group&quot;); executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy()); // 所有任务结束后关闭线程池 //executor.setWaitForTasksToCompleteOnShutdown(true); executor.initialize(); return executor; &#125;&#125; 3.2 在@Async注解上指定执行的线程池12345@Async(&quot;asyncThreadPoolTaskExecutor&quot;)@Overridepublic Future&lt;Integer&gt; searchA() &#123; try &#123; //略 以上，自定义线程池执行异步方法即完成。 3.3 自定义线程池监控自定义的线程池配置的参数是否合理往往使人摸不着头脑，实际上，线程池执行器org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor为Spring自带的，在测试中可以创建新执行器，继承该执行器，重写submit方法，对其增加监控，从而查看线程池状态，得到合适的线程池配置。 123456789101112public class MonitorThreadPoolExecutor extends ThreadPoolTaskExecutor &#123; public void monitor()&#123; log.info(&quot;**** getActiveCount==&#123;&#125;,getPoolSize==&#123;&#125;,getLargestPoolSize==&#123;&#125;,getTaskCount==&#123;&#125;,getCompletedTaskCount==&#123;&#125;,getQueue==&#123;&#125; ***&quot;,this.getThreadPoolExecutor().getActiveCount(),this.getThreadPoolExecutor().getPoolSize(),this.getThreadPoolExecutor().getLargestPoolSize(),this.getThreadPoolExecutor().getTaskCount(),this.getThreadPoolExecutor().getCompletedTaskCount(),this.getThreadPoolExecutor().getQueue().size()); &#125; @Override public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; monitor(); return super.submit(task); &#125;&#125; 在3.1自定义线程池时创建该监控执行器即可。 3.3 无返回值异步方法的异常捕获以实现org.springframework.scheduling.annotation.AsyncConfigurer接口的getAsyncExecutor方法和getAsyncUncaughtExceptionHandler方法改造配置类。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import lombok.extern.slf4j.Slf4j;import org.springframework.aop.interceptor.AsyncUncaughtExceptionHandler;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.scheduling.annotation.AsyncConfigurer;import org.springframework.scheduling.annotation.EnableAsync;import org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;import java.lang.reflect.Method;import java.util.concurrent.Executor;import java.util.concurrent.ThreadPoolExecutor;@Slf4j@EnableAsync@Configurationpublic class AsyncThreadPoolConfigure implements AsyncConfigurer &#123; //线程池创建方法为重写 getAsyncExecutor @Bean(&quot;asyncThreadPoolTaskExecutor&quot;) @Override public Executor getAsyncExecutor() &#123; ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(4); executor.setMaxPoolSize(4); executor.setQueueCapacity(10); executor.setKeepAliveSeconds(60); executor.setThreadNamePrefix(&quot;async-task-executor&quot;); executor.setThreadGroupName(&quot;async-task-executor-group&quot;); executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy()); // 所有任务结束后关闭线程池 executor.setWaitForTasksToCompleteOnShutdown(true); executor.initialize(); return executor; &#125; @Override public AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() &#123; return new AsyncExceptionHandler(); &#125; public class AsyncExceptionHandler implements AsyncUncaughtExceptionHandler &#123; @Override public void handleUncaughtException(Throwable throwable, Method method, Object... obj) &#123; log.error(&quot;Exception message is &#123;&#125;&quot;, throwable.getMessage()); log.error(&quot;Method name is &#123;&#125; &quot;, method.getName()); for (Object param : obj) &#123; log.error(&quot;Parameter value - &#123;&#125;&quot;, param); &#125; &#125; &#125; 表现如下： 1234567891011@Async(&quot;asyncThreadPoolTaskExecutor&quot;) @Override public void record() &#123; try &#123; Thread.sleep(3000); log.info(&quot;current thread name is &#123;&#125;&quot;,Thread.currentThread().getName()); throw new RuntimeException(&quot;network not connect &quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; 控制台： 123452022-04-21 15:34:14.931 INFO 16596 --- [nio-8089-exec-1] com.zang.async.web.AsyncCaseController : ========test start=========2022-04-21 15:34:16.965 INFO 16596 --- [nio-8089-exec-1] com.zang.async.web.AsyncCaseController : ========test end=========cost time is 2 seconds2022-04-21 15:34:17.939 INFO 16596 --- [-task-executor1] c.z.async.service.AsyncCaseServiceImpl : current thread name is async-task-executor12022-04-21 15:34:17.940 ERROR 16596 --- [-task-executor1] c.z.a.c.AsyncThreadPoolConfigure : Exception message is network not connect 2022-04-21 15:34:17.941 ERROR 16596 --- [-task-executor1] c.z.a.c.AsyncThreadPoolConfigure : Method name is record 4.一些思考异步方法的集成极为方便，可以有效提高接口响应速度，但是使用过程中要注意合理的分析业务逻辑及服务器资源承载能力，不可滥用。 对于强一致性的业务，需要注意，异步方法执行失败对于前部分的已执行的非异步操作是无影响的，因此在该场景异步并不可靠； 此外，对于并发量过大的任务，异步线程池的队列缓存也较为消耗服务器资源，需要合理规划，必要时建议采用更为可靠的消息队列等中间件。","categories":[{"name":"技术","slug":"技术","permalink":"https://xssdpgy.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"异步","slug":"异步","permalink":"https://xssdpgy.github.io/tags/%E5%BC%82%E6%AD%A5/"},{"name":"优化","slug":"优化","permalink":"https://xssdpgy.github.io/tags/%E4%BC%98%E5%8C%96/"}]},{"title":"二进制方式安装k8s集群","slug":"二进制方式安装k8s集群","date":"2022-03-30T07:51:45.000Z","updated":"2022-09-11T15:43:16.282Z","comments":true,"path":"2022/03/30/二进制方式安装k8s集群/","link":"","permalink":"https://xssdpgy.github.io/2022/03/30/%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%B9%E5%BC%8F%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4/","excerpt":"使用三台服务器搭建k8s集群，集群服务器地址规划如下：","text":"使用三台服务器搭建k8s集群，集群服务器地址规划如下： IP hostname 备注 192.168.206.128 master 主节点 192.168.206.129 node1 从节点 192.168.206.130 node2 从节点 1.环境配置1.1 修改主机名master: 1hostnamectl set-hostname master node1: 1hostnamectl set-hostname node1 node2: 1hostnamectl set-hostname 1.2 关闭防火墙（all）12systemctl stop firewalldsystemctl disable firewalld 1.3 关闭selinux（all）12setenforce 0 # 临时关闭sed -i &#x27;s/SELINUX=enforcing/SELINUX=disabled/g&#x27; /etc/selinux/config # 永久关闭 1.4 关闭swap（all）123swapoff -a # 临时关闭；关闭swap主要是为了性能考虑sed -ri &#x27;s/.*swap.*/#&amp;/&#x27; /etc/fstabfree # 查看内存，swap为0则为关闭 1.5 将桥接的IPv4流量传递到iptables的链（all）1234cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOFnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1EOF 1sysctl --system 1.6 添加主机名与IP对应的关系 ( master )12345cat &gt;&gt; /etc/hosts &lt;&lt; EOF 192.168.206.128 master192.168.206.129 node1192.168.206.130 node2EOF 2.准备 cfssl 证书生成工具 ( master )cfssl 是一个开源的证书管理工具，使用 json 文件生成证书，相比 openssl 更方便使用。 找任意一台服务器操作，这里用 Master 节点。 12345678wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64chmod +x cfssl_linux-amd64 cfssljson_linux-amd64 cfssl-certinfo_linux-amd64mv cfssl_linux-amd64 /usr/local/bin/cfsslmv cfssljson_linux-amd64 /usr/local/bin/cfssljsonmv cfssl-certinfo_linux-amd64 /usr/bin/cfssl-certinfochmod +x /usr/bin/cfssl* 2.1 生成 Etcd 证书 （1）自签证书颁发机构（CA） 创建工作目录123mkdir -p ~/TLS/&#123;etcd,k8s&#125;cd TLS/etcd 2.2 自签CA1234567891011121314151617181920cat &gt; ca-config.json &lt;&lt; EOF&#123; &quot;signing&quot;: &#123; &quot;default&quot;: &#123; &quot;expiry&quot;: &quot;87600h&quot; &#125;, &quot;profiles&quot;: &#123; &quot;www&quot;: &#123; &quot;expiry&quot;: &quot;87600h&quot;, &quot;usages&quot;: [ &quot;signing&quot;, &quot;key encipherment&quot;, &quot;server auth&quot;, &quot;client auth&quot; ] &#125; &#125; &#125;&#125;EOF 12345678910111213141516cat &gt; ca-csr.json &lt;&lt; EOF&#123; &quot;CN&quot;: &quot;etcd CA&quot;, &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;L&quot;: &quot;Beijing&quot;, &quot;ST&quot;: &quot;Beijing&quot; &#125; ]&#125;EOF 2.3 生成CA证书1cfssl gencert -initca ca-csr.json | cfssljson -bare ca - 12[root@master etcd]# ls ca*pem #查看ca-key.pem ca.pem 2.4 使用自签 CA 签发 Etcd HTTPS 证书 创建证书申请文件：(修改对应的master和node的IP地址)123456789101112131415161718192021cat &gt; server-csr.json &lt;&lt; EOF&#123; &quot;CN&quot;: &quot;etcd&quot;, &quot;hosts&quot;: [ &quot;192.168.206.128&quot;, &quot;192.168.206.129&quot;, &quot;192.168.206.130&quot; ], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;L&quot;: &quot;BeiJing&quot;, &quot;ST&quot;: &quot;BeiJing&quot; &#125; ]&#125;EOF 2.5 生成SERVER证书1cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=www server-csr.json | cfssljson -bare server 12[root@master etcd]# ls server*pem #查看server-key.pem server.pem 3.部署etcd集群3.1 下载12下载地址：https://github.com/etcd-io/etcd/releases版本：3.4.14 以下在master 上操作，为简化操作，完成后将master 生成的所有文件拷贝到node1 和node2。 3.2 创建工作目录并解压二进制包123mkdir /opt/etcd/&#123;bin,cfg,ssl&#125; -ptar zxvf etcd-v3.4.14-linux-amd64.tar.gzmv etcd-v3.4.14-linux-amd64/&#123;etcd,etcdctl&#125; /opt/etcd/bin/ 3.3 创建etcd.conf12345678910111213cat &gt; /opt/etcd/cfg/etcd.conf &lt;&lt; EOF#[Member]ETCD_NAME=&quot;etcd-1&quot;ETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot;ETCD_LISTEN_PEER_URLS=&quot;https://192.168.206.128:2380&quot;ETCD_LISTEN_CLIENT_URLS=&quot;https://192.168.206.128:2379&quot;#[Clustering]ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;https://192.168.206.128:2380&quot;ETCD_ADVERTISE_CLIENT_URLS=&quot;https://192.168.206.128:2379&quot;ETCD_INITIAL_CLUSTER=&quot;etcd-1=https://192.168.206.128:2380,etcd-2=https://192.168.206.129:2380,etcd-3=https://192.168.206.130:2380&quot;ETCD_INITIAL_CLUSTER_TOKEN=&quot;etcd-cluster&quot;ETCD_INITIAL_CLUSTER_STATE=&quot;new&quot;EOF ETCD_NAME：节点名称，集群中唯一 ETCD_DATA_DIR：数据目录 ETCD_LISTEN_PEER_URLS：集群通信监听地址 ETCD_LISTEN_CLIENT_URLS：客户端访问监听地址 ETCD_INITIAL_ADVERTISE_PEER_URLS：集群通告地址 ETCD_ADVERTISE_CLIENT_URLS：客户端通告地址 ETCD_INITIAL_CLUSTER：集群节点地址 ETCD_INITIAL_CLUSTER_TOKEN：集群 Token ETCD_INITIAL_CLUSTER_STATE：加入集群的当前状态，new 是新集群，existing 表示加入 已有集群 3.4 创建etcd.service12345678910111213141516171819202122cat &gt; /usr/lib/systemd/system/etcd.service &lt;&lt; EOF[Unit]Description=Etcd ServerAfter=network.targetAfter=network-online.targetWants=network-online.target[Service]Type=notifyEnvironmentFile=/opt/etcd/cfg/etcd.confExecStart=/opt/etcd/bin/etcd \\--cert-file=/opt/etcd/ssl/server.pem \\--key-file=/opt/etcd/ssl/server-key.pem \\--peer-cert-file=/opt/etcd/ssl/server.pem \\--peer-key-file=/opt/etcd/ssl/server-key.pem \\--trusted-ca-file=/opt/etcd/ssl/ca.pem \\--peer-trusted-ca-file=/opt/etcd/ssl/ca.pem \\--logger=zapRestart=on-failureLimitNOFILE=65536[Install]WantedBy=multi-user.targetEOF 3.5 拷贝上一步生成的证书到配置路径 1cp ~/TLS/etcd/ca*pem ~/TLS/etcd/server*pem /opt/etcd/ssl/ 3.6 将master 生成的所有文件拷贝到node1 和node212345scp -r /opt/etcd/ root@192.168.206.129:/opt/scp /usr/lib/systemd/system/etcd.service root@192.168.206.129:/usr/lib/systemd/system/scp -r /opt/etcd/ root@192.168.206.130:/opt/scp /usr/lib/systemd/system/etcd.service root@192.168.206.130:/usr/lib/systemd/system/ 分别修改 etcd.conf 配置文件中的节点名称和当前服务器 IP：(node1改为 etcd-2，node2 改为 etcd-3) 3.7 启动并设置开机启动1234# 三台同时执行systemctl daemon-reloadsystemctl start etcdsystemctl enable etcd 查看状态： 1234/opt/etcd/bin/etcdctl --cacert=/opt/etcd/ssl/ca.pem --cert=/opt/etcd/ssl/server.pem --key=/opt/etcd/ssl/server-key.pem --endpoints=&quot;https://192.168.206.128:2379,https://192.168.206.129:2379,https://192.168.206.130:2379&quot; endpoint health#可视化展示/opt/etcd/bin/etcdctl --cacert=/opt/etcd/ssl/ca.pem --cert=/opt/etcd/ssl/server.pem --key=/opt/etcd/ssl/server-key.pem --endpoints=&quot;https://192.168.206.128:2379,https://192.168.206.129:2379,https://192.168.206.130:2379&quot; endpoint status --write-out=table 4.安装docker（all）4.1 下载12下载地址：https://download.docker.com/linux/static/stable/x86_64/版本：19.03.9 4.2 解压及安装12tar zxvf docker-19.03.9.tgz mv docker/* /usr/bin 4.3 systemd 管理 docker12345678910111213141516171819202122cat &gt; /usr/lib/systemd/system/docker.service &lt;&lt; EOF[Unit]Description=Docker Application Container EngineDocumentation=https://docs.docker.comAfter=network-online.target firewalld.serviceWants=network-online.target[Service]Type=notifyExecStart=/usr/bin/dockerdExecReload=/bin/kill -s HUP $MAINPIDLimitNOFILE=infinityLimitNPROC=infinityLimitCORE=infinityTimeoutStartSec=0Delegate=yesKillMode=processRestart=on-failureStartLimitBurst=3StartLimitInterval=60s[Install]WantedBy=multi-user.targetEOF 4.4 配置阿里云加速123456mkdir /etc/dockercat &gt; /etc/docker/daemon.json &lt;&lt; EOF&#123; &quot;registry-mirrors&quot;: [&quot;https://b9pmyelo.mirror.aliyuncs.com&quot;]&#125;EOF 4.5 启动并设置开机启动123systemctl daemon-reloadsystemctl start dockersystemctl enable docker 4.6 查询是否安装成功12[root@master etcd]# docker -vDocker version 19.03.9, build 9d988398e7 5.部署Master Node（master）5.1 生成 kube-apiserver 证书 自签证书颁发机构（CA）1cd TLS/k8s 1234567891011121314151617181920cat &gt; ca-config.json &lt;&lt; EOF&#123; &quot;signing&quot;: &#123; &quot;default&quot;: &#123; &quot;expiry&quot;: &quot;87600h&quot; &#125;, &quot;profiles&quot;: &#123; &quot;kubernetes&quot;: &#123; &quot;expiry&quot;: &quot;87600h&quot;, &quot;usages&quot;: [ &quot;signing&quot;, &quot;key encipherment&quot;, &quot;server auth&quot;, &quot;client auth&quot; ] &#125; &#125; &#125;&#125;EOF 123456789101112131415161718cat &gt; ca-csr.json &lt;&lt; EOF&#123; &quot;CN&quot;: &quot;kubernetes&quot;, &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;L&quot;: &quot;Beijing&quot;, &quot;ST&quot;: &quot;Beijing&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;System&quot; &#125; ]&#125;EOF 5.2 生成CA证书1cfssl gencert -initca ca-csr.json | cfssljson -bare ca - 12[root@master k8s]# ls ca*pem #查看ca-key.pem ca.pem 5.3 使用自签 CA 签发 kube-apiserver HTTPS 证书 创建证书申请文件12345678910111213141516171819202122232425262728293031cat &gt; server-csr.json &lt;&lt; EOF&#123; &quot;CN&quot;: &quot;kubernetes&quot;, &quot;hosts&quot;: [ &quot;10.0.0.1&quot;, &quot;127.0.0.1&quot;, &quot;192.168.206.128&quot;, &quot;192.168.206.129&quot;, &quot;192.168.206.130&quot;, &quot;192.168.206.131&quot;, &quot;kubernetes&quot;, &quot;kubernetes.default&quot;, &quot;kubernetes.default.svc&quot;, &quot;kubernetes.default.svc.cluster&quot;, &quot;kubernetes.default.svc.cluster.local&quot; ], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;L&quot;: &quot;BeiJing&quot;, &quot;ST&quot;: &quot;BeiJing&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;System&quot; &#125; ]&#125;EOF 注：192.168.206.131为预留出的IP。 5.4 生成SERVER证书1cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes server-csr.json | cfssljson -bare server 12[root@master k8s]# ls server*pem #查看server-key.pem server.pem 5.5 下载k8s安装包并解压12下载地址：https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.18.md#server-binaries版本：1.18.20 (压缩包名：kubernetes-server-linux-amd64.tar.gz) 12345mkdir -p /opt/kubernetes/&#123;bin,cfg,ssl,logs&#125;tar zxvf kubernetes-server-linux-amd64.tar.gzcd kubernetes/server/bincp kube-apiserver kube-scheduler kube-controller-manager /opt/kubernetes/bincp kubectl /usr/bin/ 5.6 部署kube-apiserver123456789101112131415161718192021222324252627282930cat &gt; /opt/kubernetes/cfg/kube-apiserver.conf &lt;&lt; EOFKUBE_APISERVER_OPTS=&quot;--logtostderr=false \\\\--v=2 \\\\--log-dir=/opt/kubernetes/logs \\\\--etcd-servers=https://192.168.206.128:2379,https://192.168.206.129:2379,https://192.168.206.130:2379 \\\\--bind-address=192.168.206.128 \\\\--secure-port=6443 \\\\--advertise-address=192.168.206.128 \\\\--allow-privileged=true \\\\--service-cluster-ip-range=10.0.0.0/24 \\\\--enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,ResourceQuota,NodeRestriction \\\\--authorization-mode=RBAC,Node \\\\--enable-bootstrap-token-auth=true \\\\--token-auth-file=/opt/kubernetes/cfg/token.csv \\\\--service-node-port-range=30000-32767 \\\\--kubelet-client-certificate=/opt/kubernetes/ssl/server.pem \\\\--kubelet-client-key=/opt/kubernetes/ssl/server-key.pem \\\\--tls-cert-file=/opt/kubernetes/ssl/server.pem \\\\--tls-private-key-file=/opt/kubernetes/ssl/server-key.pem \\\\--client-ca-file=/opt/kubernetes/ssl/ca.pem \\\\--service-account-key-file=/opt/kubernetes/ssl/ca-key.pem \\\\--etcd-cafile=/opt/etcd/ssl/ca.pem \\\\--etcd-certfile=/opt/etcd/ssl/server.pem \\\\--etcd-keyfile=/opt/etcd/ssl/server-key.pem \\\\--audit-log-maxage=30 \\\\--audit-log-maxbackup=3 \\\\--audit-log-maxsize=100 \\\\--audit-log-path=/opt/kubernetes/logs/k8s-audit.log&quot;EOF 上面两个\\ \\ 第一个是转义符，第二个是换行符，使用转义符是为了使用 EOF 保留换行符。 –logtostderr：启用日志 —v：日志等级 –log-dir：日志目录 –etcd-servers：etcd 集群地址 –bind-address：监听地址 –secure-port：https 安全端口 –advertise-address：集群通告地址 –allow-privileged：启用授权 –service-cluster-ip-range：Service 虚拟 IP 地址段 –enable-admission-plugins：准入控制模块 –authorization-mode：认证授权，启用 RBAC 授权和节点自管理 –enable-bootstrap-token-auth：启用 TLS bootstrap 机制 –token-auth-file：bootstrap token 文件 –service-node-port-range：Service nodeport 类型默认分配端口范围 –kubelet-client-xxx：apiserver 访问 kubelet 客户端证书 –tls-xxx-file：apiserver https 证书 –etcd-xxxfile：连接 Etcd 集群证书 –audit-log-xxx：审计日志 5.7 把生成的证书拷贝到配置文件中的路径1cp ~/TLS/k8s/ca*pem ~/TLS/k8s/server*pem /opt/kubernetes/ssl/ 5.8 创建上述配置文件中 token 文件123cat &gt; /opt/kubernetes/cfg/token.csv &lt;&lt; EOFc47ffb939f5ca36231d9e3121a252940,kubelet-bootstrap,10001,&quot;system:node-bootstrapper&quot;EOF 格式：token，用户名，UID，用户组 token 也可自行生成替换： 1head -c 16 /dev/urandom | od -An -t x | tr -d &#x27; &#x27; 5.9 systemd 管理 apiserver1234567891011cat &gt; /usr/lib/systemd/system/kube-apiserver.service &lt;&lt; EOF[Unit]Description=Kubernetes API ServerDocumentation=https://github.com/kubernetes/kubernetes[Service]EnvironmentFile=/opt/kubernetes/cfg/kube-apiserver.confExecStart=/opt/kubernetes/bin/kube-apiserver \\$KUBE_APISERVER_OPTSRestart=on-failure[Install]WantedBy=multi-user.targetEOF 启动并设置开机启动 123systemctl daemon-reloadsystemctl start kube-apiserversystemctl enable kube-apiserver 5.10 授权 kubelet-bootstrap 用户允许请求证书123kubectl create clusterrolebinding kubelet-bootstrap \\--clusterrole=system:node-bootstrapper \\--user=kubelet-bootstrap 5.11 部署 kube-controller-manager12345678910111213141516cat &gt; /opt/kubernetes/cfg/kube-controller-manager.conf &lt;&lt; EOFKUBE_CONTROLLER_MANAGER_OPTS=&quot;--logtostderr=false \\\\--v=2 \\\\--log-dir=/opt/kubernetes/logs \\\\--leader-elect=true \\\\--master=127.0.0.1:8080 \\\\--bind-address=127.0.0.1 \\\\--allocate-node-cidrs=true \\\\--cluster-cidr=10.244.0.0/16 \\\\--service-cluster-ip-range=10.0.0.0/24 \\\\--cluster-signing-cert-file=/opt/kubernetes/ssl/ca.pem \\\\--cluster-signing-key-file=/opt/kubernetes/ssl/ca-key.pem \\\\--root-ca-file=/opt/kubernetes/ssl/ca.pem \\\\--service-account-private-key-file=/opt/kubernetes/ssl/ca-key.pem \\\\--experimental-cluster-signing-duration=87600h0m0s&quot;EOF –master：通过本地非安全本地端口 8080 连接 apiserver –leader-elect：当该组件启动多个时，自动选举（HA） –cluster-signing-cert-file&#x2F;–cluster-signing-key-file：自动为 kubelet 颁发证书的 CA，与 apiserver 保持一致 5.12 systemd 管理 controller-manager1234567891011cat &gt; /usr/lib/systemd/system/kube-controller-manager.service &lt;&lt; EOF[Unit]Description=Kubernetes Controller ManagerDocumentation=https://github.com/kubernetes/kubernetes[Service]EnvironmentFile=/opt/kubernetes/cfg/kube-controller-manager.confExecStart=/opt/kubernetes/bin/kube-controller-manager \\$KUBE_CONTROLLER_MANAGER_OPTSRestart=on-failure[Install]WantedBy=multi-user.targetEOF 启动并设置开机启动 123systemctl daemon-reloadsystemctl start kube-controller-managersystemctl enable kube-controller-manager 5.13 部署 kube-scheduler12345678cat &gt; /opt/kubernetes/cfg/kube-scheduler.conf &lt;&lt; EOFKUBE_SCHEDULER_OPTS=&quot;--logtostderr=false \\--v=2 \\--log-dir=/opt/kubernetes/logs \\--leader-elect \\--master=127.0.0.1:8080 \\--bind-address=127.0.0.1&quot;EOF –master：通过本地非安全本地端口 8080 连接 apiserver –leader-elect：当该组件启动多个时，自动选举（HA） 1234567891011cat &gt; /usr/lib/systemd/system/kube-scheduler.service &lt;&lt; EOF[Unit]Description=Kubernetes SchedulerDocumentation=https://github.com/kubernetes/kubernetes[Service]EnvironmentFile=/opt/kubernetes/cfg/kube-scheduler.confExecStart=/opt/kubernetes/bin/kube-scheduler \\$KUBE_SCHEDULER_OPTSRestart=on-failure[Install]WantedBy=multi-user.targetEOF 启动并设置开机启动 123systemctl daemon-reloadsystemctl start kube-schedulersystemctl enable kube-scheduler 5.14 查看集群状态1kubectl get cs 6.部署Worker Node（两个node同步执行）6.1k8s安装包解压安装12345mkdir -p /opt/kubernetes/&#123;bin,cfg,ssl,logs&#125;tar zxvf kubernetes-server-linux-amd64.tar.gzcd kubernetes/server/bincp kubelet kube-proxy /opt/kubernetes/bincp kubectl /usr/bin/ 6.2 配置kubelet123456789101112cat &gt; /opt/kubernetes/cfg/kubelet.conf &lt;&lt; EOFKUBELET_OPTS=&quot;--logtostderr=false \\\\--v=2 \\\\--log-dir=/opt/kubernetes/logs \\\\--hostname-override=m1 \\\\--network-plugin=cni \\\\--kubeconfig=/opt/kubernetes/cfg/kubelet.kubeconfig \\\\--bootstrap-kubeconfig=/opt/kubernetes/cfg/bootstrap.kubeconfig \\\\--config=/opt/kubernetes/cfg/kubelet-config.yml \\\\--cert-dir=/opt/kubernetes/ssl \\\\--pod-infra-container-image=lizhenliang/pause-amd64:3.0&quot;EOF –hostname-override：显示名称，集群中唯一 –network-plugin：启用CNI –kubeconfig：空路径，会自动生成，后面用于连接apiserver –bootstrap-kubeconfig：首次启动向apiserver申请证书 –config：配置参数文件 –cert-dir：kubelet证书生成目录 –pod-infra-container-image：管理Pod网络容器的镜像 1234567891011121314151617181920212223242526272829303132cat &gt; /opt/kubernetes/cfg/kubelet-config.yml &lt;&lt; EOFkind: KubeletConfigurationapiVersion: kubelet.config.k8s.io/v1beta1address: 0.0.0.0port: 10250readOnlyPort: 10255cgroupDriver: cgroupfsclusterDNS:- 10.0.0.2clusterDomain: cluster.local failSwapOn: falseauthentication: anonymous: enabled: false webhook: cacheTTL: 2m0s enabled: true x509: clientCAFile: /opt/kubernetes/ssl/ca.pem authorization: mode: Webhook webhook: cacheAuthorizedTTL: 5m0s cacheUnauthorizedTTL: 30sevictionHard: imagefs.available: 15% memory.available: 100Mi nodefs.available: 10% nodefs.inodesFree: 5%maxOpenFiles: 1000000maxPods: 110EOF 6.3 将master一些配置文件拷贝到node节点上12scp -r /opt/kubernetes/ssl root@192.168.206.129:/opt/kubernetesscp -r /opt/kubernetes/ssl root@192.168.206.130:/opt/kubernetes 6.4 生成bootstrap.kubeconfig文件12KUBE_APISERVER=&quot;https://192.168.206.128:6443&quot; # apiserver IP:PORTTOKEN=&quot;c47ffb939f5ca36231d9e3121a252940&quot; # 与token.csv里保持一致 上面两个变量需要根据自己情况设置，赋到脚本对应位置执行： 12345678910111213kubectl config set-cluster kubernetes \\ --certificate-authority=/opt/kubernetes/ssl/ca.pem \\ --embed-certs=true \\ --server=$&#123;KUBE_APISERVER&#125; \\ --kubeconfig=bootstrap.kubeconfigkubectl config set-credentials &quot;kubelet-bootstrap&quot; \\ --token=$&#123;TOKEN&#125; \\ --kubeconfig=bootstrap.kubeconfigkubectl config set-context default \\ --cluster=kubernetes \\ --user=&quot;kubelet-bootstrap&quot; \\ --kubeconfig=bootstrap.kubeconfigkubectl config use-context default --kubeconfig=bootstrap.kubeconfig 1mv bootstrap.kubeconfig /opt/kubernetes/cfg 6.5 systemd管理kubelet123456789101112cat &gt; /usr/lib/systemd/system/kubelet.service &lt;&lt; EOF[Unit]Description=Kubernetes KubeletAfter=docker.service[Service]EnvironmentFile=/opt/kubernetes/cfg/kubelet.confExecStart=/opt/kubernetes/bin/kubelet \\$KUBELET_OPTSRestart=on-failureLimitNOFILE=65536[Install]WantedBy=multi-user.targetEOF 启动并设置开机启动 123systemctl daemon-reloadsystemctl start kubeletsystemctl enable kubelet 6.7 批准kubelet证书申请并加入集群（master执行）1234567891011# 查看kubelet证书请求kubectl get csrNAME AGE SIGNERNAME REQUESTOR CONDITIONnode-csr-uCEGPOIiDdlLODKts8J658HrFq9CZ--K6M4G7bjhk8A 6m3s kubernetes.io/kube-apiserver-client-kubelet kubelet-bootstrap Pendingnode-csr-***# 批准申请kubectl certificate approve node-csr-uCEGPOIiDdlLODKts8J658HrFq9CZ--K6M4G7bjhk8Akubectl certificate approve node-csr-***# 查看节点kubectl get node 由于网络插件还没有部署，节点会没有准备就绪 NotReady。 6.8 部署kube-proxy123456cat &gt; /opt/kubernetes/cfg/kube-proxy.conf &lt;&lt; EOFKUBE_PROXY_OPTS=&quot;--logtostderr=false \\\\--v=2 \\\\--log-dir=/opt/kubernetes/logs \\\\--config=/opt/kubernetes/cfg/kube-proxy-config.yml&quot;EOF 12345678910cat &gt; /opt/kubernetes/cfg/kube-proxy-config.yml &lt;&lt; EOFkind: KubeProxyConfigurationapiVersion: kubeproxy.config.k8s.io/v1alpha1bindAddress: 0.0.0.0metricsBindAddress: 0.0.0.0:10249clientConnection: kubeconfig: /opt/kubernetes/cfg/kube-proxy.kubeconfighostnameOverride: node1clusterCIDR: 10.0.0.0/24EOF hostnameOverride设置对应node机器的hostname。 6.9 生成kube-proxy.kubeconfig文件（master生成传到node）1234567891011121314151617181920212223# 切换工作目录cd TLS/k8s# 创建证书请求文件cat &gt; kube-proxy-csr.json &lt;&lt; EOF&#123; &quot;CN&quot;: &quot;system:kube-proxy&quot;, &quot;hosts&quot;: [], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;L&quot;: &quot;BeiJing&quot;, &quot;ST&quot;: &quot;BeiJing&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;System&quot; &#125; ]&#125;EOF 12# 生成证书cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kube-proxy-csr.json | cfssljson -bare kube-proxy 12[root@master k8s]# ls kube-proxy*pemkube-proxy-key.pem kube-proxy.pem 将master生成的证书传输到node 12scp /root/TLS/k8s/kube-proxy*pem root@192.168.206.129:/opt/kubernetes/sslscp /root/TLS/k8s/kube-proxy*pem root@192.168.206.130:/opt/kubernetes/ssl 6.10 生成kubeconfig文件1KUBE_APISERVER=&quot;https://192.168.206.128:6443&quot; # apiserver IP:PORT 123456789101112131415kubectl config set-cluster kubernetes \\ --certificate-authority=/opt/kubernetes/ssl/ca.pem \\ --embed-certs=true \\ --server=$&#123;KUBE_APISERVER&#125; \\ --kubeconfig=kube-proxy.kubeconfigkubectl config set-credentials kube-proxy \\ --client-certificate=/opt/kubernetes/ssl/kube-proxy.pem \\ --client-key=/opt/kubernetes/ssl/kube-proxy-key.pem \\ --embed-certs=true \\ --kubeconfig=kube-proxy.kubeconfigkubectl config set-context default \\ --cluster=kubernetes \\ --user=kube-proxy \\ --kubeconfig=kube-proxy.kubeconfigkubectl config use-context default --kubeconfig=kube-proxy.kubeconfig 6.11 systemd管理kube-proxy123456789101112cat &gt; /usr/lib/systemd/system/kube-proxy.service &lt;&lt; EOF[Unit]Description=Kubernetes ProxyAfter=network.target[Service]EnvironmentFile=/opt/kubernetes/cfg/kube-proxy.confExecStart=/opt/kubernetes/bin/kube-proxy \\$KUBE_PROXY_OPTSRestart=on-failureLimitNOFILE=65536[Install]WantedBy=multi-user.targetEOF 启动并设置开机启动： 123systemctl daemon-reloadsystemctl start kube-proxysystemctl enable kube-proxy 7.部署CNI网络下载安装 12下载地址：https://github.com/containernetworking/plugins/releases版本：v0.8.6（安装包名：cni-plugins-linux-amd64-v0.8.6.tgz） node节点操作： 12mkdir /opt/cni/bintar zxvf cni-plugins-linux-amd64-v0.8.6.tgz -C /opt/cni/bin master节点操作： 12wget --no-check-certificate https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.ymlkubectl apply -f kube-flannel.yml 参考： 【尚硅谷】Kubernetes（k8s）入门到实战教程丨全新升级完整版 k8s集群 (二进制安装方式)","categories":[{"name":"技术","slug":"技术","permalink":"https://xssdpgy.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://xssdpgy.github.io/tags/k8s/"},{"name":"安装","slug":"安装","permalink":"https://xssdpgy.github.io/tags/%E5%AE%89%E8%A3%85/"}]}],"categories":[{"name":"技术","slug":"技术","permalink":"https://xssdpgy.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"异步","slug":"异步","permalink":"https://xssdpgy.github.io/tags/%E5%BC%82%E6%AD%A5/"},{"name":"优化","slug":"优化","permalink":"https://xssdpgy.github.io/tags/%E4%BC%98%E5%8C%96/"},{"name":"k8s","slug":"k8s","permalink":"https://xssdpgy.github.io/tags/k8s/"},{"name":"安装","slug":"安装","permalink":"https://xssdpgy.github.io/tags/%E5%AE%89%E8%A3%85/"}]}
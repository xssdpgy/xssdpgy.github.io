{"meta":{"title":"雪山上的蒲公英","subtitle":"JinFeng's Blog","description":"Stay hungry, Stay foolish.","author":"Zang JinFeng","url":"https://xssdpgy.github.io","root":"/"},"pages":[{"title":"关于","date":"2022-04-07T06:04:21.000Z","updated":"2022-09-11T15:43:16.282Z","comments":false,"path":"about/index.html","permalink":"https://xssdpgy.github.io/about/index.html","excerpt":"","text":"程序员一枚，专向互金工程领域。"},{"title":"分类","date":"2022-04-06T15:33:39.000Z","updated":"2022-09-11T15:43:16.282Z","comments":false,"path":"categories/index.html","permalink":"https://xssdpgy.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2022-04-06T15:31:49.000Z","updated":"2022-09-11T15:43:16.283Z","comments":false,"path":"tags/index.html","permalink":"https://xssdpgy.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"代理模式——JDK动态代理与CGLib原理及对比分析","slug":"代理模式——CGLib与JDK动态代理原理及对比分析","date":"2022-10-12T16:05:28.000Z","updated":"2022-10-15T17:17:35.838Z","comments":true,"path":"2022/10/13/代理模式——CGLib与JDK动态代理原理及对比分析/","link":"","permalink":"https://xssdpgy.github.io/2022/10/13/%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94CGLib%E4%B8%8EJDK%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AF%B9%E6%AF%94%E5%88%86%E6%9E%90/","excerpt":"1.前言首先回顾下代理模式（Proxy Pattern）的定义：代理模式指为其他对象提供一种代理，以控制这个对象的访问，属于结构型设计模式。其适用于在某些情况下，一个对象不适合或者不能直接引用另一个对象，而代理对象可以在客户端于目标对象之间起到中介的作用。","text":"1.前言首先回顾下代理模式（Proxy Pattern）的定义：代理模式指为其他对象提供一种代理，以控制这个对象的访问，属于结构型设计模式。其适用于在某些情况下，一个对象不适合或者不能直接引用另一个对象，而代理对象可以在客户端于目标对象之间起到中介的作用。 代理模式主要分为静态代理和动态代理两种方式，静态代理需要手动创建代理类，代理的目标对象是固定的；动态代理使用反射机制，代理的目标对象是活动的，不需要创建代理类即可给不同的目标随时创建代理。本篇重点探究动态代理的实现。 2.JDK动态代理JDK动态代理采用字节重组，重新生成对象来替代原始对象，以达到动态代理的目的。JDK动态代理生成对象的步骤如下： 获取被代理对象的引用，并且获取它的所有接口，反射获取。 JDK动态代理类重新生成一个新的类，同时新的类要实现被代理类实现的所有接口。 动态生成Java代码，新加的业务逻辑方法由一定的逻辑代码调用（在代码中体现）。 编译新生成的Java代码.class文件。 重新加载到JVM中运行。 2.1 JDK动态代理实现及原理源码解析实现一个JDK动态代理，方式为实现java.lang.reflect.InvocationHandler接口，并使用java.lang.reflect.Proxy.newProxyInstance()方法生成代理对象。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/*** 要代理的接口*/public interface IPerson &#123; void learn();&#125;/*** 真实调用类*/public class Zhangsan implements IPerson &#123; public void learn() &#123; System.out.println(&quot;==张三学习中间件==&quot;); &#125;&#125;/*** JDK代理类生成*/import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;public class JdkInvocationHandler implements InvocationHandler &#123; private IPerson target; public IPerson getInstance(IPerson target)&#123; this.target = target; Class&lt;?&gt; clazz = target.getClass(); return (IPerson) Proxy.newProxyInstance(clazz.getClassLoader(),clazz.getInterfaces(),this); &#125; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; before(); Object result = method.invoke(this.target,args); after(); return result; &#125; private void before() &#123; System.out.println(&quot;事前做好计划&quot;); &#125; private void after() &#123; System.out.println(&quot;事后回顾梳理&quot;); &#125;&#125;/*** 测试*/public class TestProxy &#123; public static void main(String[] args) &#123; try &#123; //把生成的字节码保存到本地磁盘,动态生成的类会保存在工程根目录下的 com/sun/proxy 目录里面 System.setProperty(&quot;sun.misc.ProxyGenerator.saveGeneratedFiles&quot;,&quot;true&quot;); IPerson obj = (IPerson) new JdkInvocationHandler().getInstance(new Zhangsan()); obj.learn(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 看下 Proxy.newProxyInstance 里面究竟发生了什么？ 结合流程图，在生成字节码的那个地方，也就是 ProxyGenerator.generateProxyClass() 方法里面，通过代码可以看到（自行查阅，篇幅原因，这里不贴代码），里面是用参数 saveGeneratedFiles 来控制是否把生成的字节码保存到本地磁盘。代码中已经设置保存到本地，现在找到刚才生成的 $Proxy0.class，反编译打开如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071import com.zang.jdkproxy.IPerson;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.lang.reflect.UndeclaredThrowableException;public final class $Proxy0 extends Proxy implements IPerson &#123; private static Method m1; private static Method m3; private static Method m2; private static Method m0; public $Proxy0(InvocationHandler var1) throws &#123; super(var1); &#125; public final boolean equals(Object var1) throws &#123; try &#123; return (Boolean)super.h.invoke(this, m1, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; public final void learn() throws &#123; try &#123; // super.h 对应的是父类的h变量，也就是Proxy.newProxyInstance方法中的InvocationHandler参数 // 所以这里实际上就是使用了我们自己写的InvocationHandler实现类的invoke方法 super.h.invoke(this, m3, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; public final String toString() throws &#123; try &#123; return (String)super.h.invoke(this, m2, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; public final int hashCode() throws &#123; try &#123; return (Integer)super.h.invoke(this, m0, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; static &#123; try &#123; m1 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;equals&quot;, Class.forName(&quot;java.lang.Object&quot;)); m3 = Class.forName(&quot;com.zang.jdkproxy.IPerson&quot;).getMethod(&quot;learn&quot;); m2 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;toString&quot;); m0 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;hashCode&quot;); &#125; catch (NoSuchMethodException var2) &#123; throw new NoSuchMethodError(var2.getMessage()); &#125; catch (ClassNotFoundException var3) &#123; throw new NoClassDefFoundError(var3.getMessage()); &#125; &#125;&#125; 可以看到 $Proxy0类继承了Proxy类，里面有一个跟IPerson一样签名的 learn 方法，方法实现中的super.h.invoke(this, m3, (Object[])null);，super.h 对应的是父类的h变量，也就是Proxy.newProxyInstance方法中的InvocationHandler参数： 12345678910111213141516171819202122package java.lang.reflect;//import略public class Proxy implements java.io.Serializable &#123; protected InvocationHandler h; protected Proxy(InvocationHandler h) &#123; Objects.requireNonNull(h); this.h = h; &#125; @CallerSensitive public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException &#123; Objects.requireNonNull(h); final Class&lt;?&gt;[] intfs = interfaces.clone(); // 所以这里实际上就是使用了我自己写的InvocationHandler实现类JdkInvocationHandler的invoke方法，当调用 IPerson.learn的时候，其实它是被转发到了 JdkInvocationHandler.invoke。至此，整个魔术过程就透明了。 2.2 手写JDK动态代理使用JDK动态代理的类名和方法名定义以及执行思路，下面来进行手写实现。 创建MyInvocationHandler接口：123456import java.lang.reflect.Method;public interface MyInvocationHandler &#123; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable;&#125; 创建MyProxy类：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147import javax.tools.JavaCompiler;import javax.tools.StandardJavaFileManager;import javax.tools.ToolProvider;import java.io.File;import java.io.FileWriter;import java.lang.reflect.Constructor;import java.lang.reflect.Method;import java.util.HashMap;import java.util.Map;/** * 自己实现的代理类，用来生成字节码文件，并动态加载到JVM中 */public class MyProxy &#123; public static final String ln = &quot;\\r\\n&quot;; /** * 生成代理对象 * @param classLoader 类加载器，用于加载被代理类的类文件 * @param interfaces 被代理类的接口 * @param h 自定义的InvocationHandler接口,用于具体代理方法的执行 * @return 返回被代理后的代理对象 */ public static Object newProxyInstance(MyClassLoader classLoader, Class&lt;?&gt;[] interfaces, MyInvocationHandler h) &#123; try &#123; //1、动态生成源代码.java文件 String src = generateSrc(interfaces); //2、Java文件输出磁盘 String filePath = MyProxy.class.getResource(&quot;&quot;).getPath(); File f = new File(filePath + &quot;$Proxy0.java&quot;); FileWriter fw = new FileWriter(f); fw.write(src); fw.flush(); fw.close(); //3、把生成的.java文件编译成.class文件 //获取Java编译器 JavaCompiler compiler = ToolProvider.getSystemJavaCompiler(); //标注Java文件管理器，用来获取Java字节码文件 StandardJavaFileManager manage = compiler.getStandardFileManager(null, null, null); Iterable iterable = manage.getJavaFileObjects(f); //创建task，通过java字节码文件将类信息加载到JVM中 JavaCompiler.CompilationTask task = compiler.getTask(null, manage, null, null, null, iterable); //开始执行task task.call(); //关闭管理器 manage.close(); //4、编译生成的.class文件加载到JVM中来 Class proxyClass = classLoader.findClass(&quot;$Proxy0&quot;); Constructor c = proxyClass.getConstructor(MyInvocationHandler.class); f.delete(); //5、返回字节码重组以后的新的代理对象 return c.newInstance(h); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; /** * 生成代理类的源代码 */ private static String generateSrc(Class&lt;?&gt;[] interfaces) &#123; StringBuffer sb = new StringBuffer(); sb.append(MyProxy.class.getPackage() + &quot;;&quot; + ln); sb.append(&quot;import &quot; + interfaces[0].getName() + &quot;;&quot; + ln); sb.append(&quot;import java.lang.reflect.*;&quot; + ln); sb.append(&quot;public class $Proxy0 implements &quot; + interfaces[0].getName() + &quot;&#123;&quot; + ln); sb.append(&quot;GPInvocationHandler h;&quot; + ln); sb.append(&quot;public $Proxy0(GPInvocationHandler h) &#123; &quot; + ln); sb.append(&quot;this.h = h;&quot;); sb.append(&quot;&#125;&quot; + ln); for (Method m : interfaces[0].getMethods()) &#123; Class&lt;?&gt;[] params = m.getParameterTypes(); StringBuffer paramNames = new StringBuffer(); StringBuffer paramValues = new StringBuffer(); StringBuffer paramClasses = new StringBuffer(); for (int i = 0; i &lt; params.length; i++) &#123; Class clazz = params[i]; String type = clazz.getName(); String paramName = toLowerFirstCase(clazz.getSimpleName()); paramNames.append(type + &quot; &quot; + paramName); paramValues.append(paramName); paramClasses.append(clazz.getName() + &quot;.class&quot;); if (i &gt; 0 &amp;&amp; i &lt; params.length - 1) &#123; paramNames.append(&quot;,&quot;); paramClasses.append(&quot;,&quot;); paramValues.append(&quot;,&quot;); &#125; &#125; sb.append(&quot;public &quot; + m.getReturnType().getName() + &quot; &quot; + m.getName() + &quot;(&quot; + paramNames.toString() + &quot;) &#123;&quot; + ln); sb.append(&quot;try&#123;&quot; + ln); sb.append(&quot;Method m = &quot; + interfaces[0].getName() + &quot;.class.getMethod(\\&quot;&quot; + m.getName() + &quot;\\&quot;,new Class[]&#123;&quot; + paramClasses.toString() + &quot;&#125;);&quot; + ln); sb.append((hasReturnValue(m.getReturnType()) ? &quot;return &quot; : &quot;&quot;) + getCaseCode(&quot;this.h.invoke(this,m,new Object[]&#123;&quot; + paramValues + &quot;&#125;)&quot;, m.getReturnType()) + &quot;;&quot; + ln); sb.append(&quot;&#125;catch(Error _ex) &#123; &#125;&quot;); sb.append(&quot;catch(Throwable e)&#123;&quot; + ln); sb.append(&quot;throw new UndeclaredThrowableException(e);&quot; + ln); sb.append(&quot;&#125;&quot;); sb.append(getReturnEmptyCode(m.getReturnType())); sb.append(&quot;&#125;&quot;); &#125; sb.append(&quot;&#125;&quot; + ln); return sb.toString(); &#125; private static Map&lt;Class, Class&gt; mappings = new HashMap&lt;Class, Class&gt;(); static &#123; mappings.put(int.class, Integer.class); &#125; private static String getReturnEmptyCode(Class&lt;?&gt; returnClass) &#123; if (mappings.containsKey(returnClass)) &#123; return &quot;return 0;&quot;; &#125; else if (returnClass == void.class) &#123; return &quot;&quot;; &#125; else &#123; return &quot;return null;&quot;; &#125; &#125; private static String getCaseCode(String code, Class&lt;?&gt; returnClass) &#123; if (mappings.containsKey(returnClass)) &#123; return &quot;((&quot; + mappings.get(returnClass).getName() + &quot;)&quot; + code + &quot;).&quot; + returnClass.getSimpleName() + &quot;Value()&quot;; &#125; return code; &#125; private static boolean hasReturnValue(Class&lt;?&gt; clazz) &#123; return clazz != void.class; &#125; private static String toLowerFirstCase(String src) &#123; char[] chars = src.toCharArray(); chars[0] += 32; return String.valueOf(chars); &#125;&#125; 创建类加载器MyClassLoader：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import java.io.ByteArrayOutputStream;import java.io.File;import java.io.FileInputStream;public class MyClassLoader extends ClassLoader &#123; private File classPathFile; public MyClassLoader()&#123; String classPath = MyClassLoader.class.getResource(&quot;&quot;).getPath(); this.classPathFile = new File(classPath); &#125; /** * 通过类名称加载类字节码文件到JVM中 * @param name 类名 * @return 类的Class独享 * @throws ClassNotFoundException */ @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; //获取类名 String className = MyClassLoader.class.getPackage().getName() + &quot;.&quot; + name; if(classPathFile != null)&#123; //获取类文件 File classFile = new File(classPathFile,name.replaceAll(&quot;\\\\.&quot;,&quot;/&quot;) + &quot;.class&quot;); if(classFile.exists())&#123; //将类文件转化为字节数组 FileInputStream in = null; ByteArrayOutputStream out = null; try&#123; in = new FileInputStream(classFile); out = new ByteArrayOutputStream(); byte [] buff = new byte[1024]; int len; while ((len = in.read(buff)) != -1)&#123; out.write(buff,0,len); &#125; //调用父类方法生成class实例 return defineClass(className,out.toByteArray(),0,out.size()); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; &#125; &#125; return null; &#125;&#125; 实现并测试12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/*** 要代理的接口*/public interface IPerson &#123; void learn();&#125;/*** 真实调用类*/public class Zhangsan implements IPerson &#123; public void learn() &#123; System.out.println(&quot;==张三学习中间件==&quot;); &#125;&#125;/*** JDK代理类生成*/public class CustomInvocationHandler implements MyInvocationHandler &#123; private IPerson target; public IPerson getInstance(IPerson target)&#123; this.target = target; Class&lt;?&gt; clazz = target.getClass(); return (IPerson) MyProxy.newProxyInstance(new MyClassLoader(),clazz.getInterfaces(),this); &#125; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; before(); Object result = method.invoke(this.target,args); after(); return result; &#125; private void before() &#123; System.out.println(&quot;事前做好计划&quot;); &#125; private void after() &#123; System.out.println(&quot;事后回顾梳理&quot;); &#125;&#125;/*** 测试*/public class Test &#123; public static void main(String[] args) &#123; CustomInvocationHandler custom = new CustomInvocationHandler(); IPerson zhangsan = custom.getInstance(new Zhangsan()); zhangsan.learn(); &#125;&#125; 至此，手写完成，读者也可自行参照实现。 3.CGLib动态代理API原理分析3.1 CGLib动态代理的使用1234567891011121314151617181920212223242526272829303132import net.sf.cglib.proxy.Enhancer;import net.sf.cglib.proxy.MethodInterceptor;import net.sf.cglib.proxy.MethodProxy;import java.lang.reflect.Method;public class CustomCGlib implements MethodInterceptor &#123; public Object getInstance(Class&lt;?&gt; clazz) throws Exception&#123; //相当于Proxy，代理的工具类 Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(clazz); enhancer.setCallback(this); return enhancer.create(); &#125; public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; before(); Object obj = methodProxy.invokeSuper(o,objects); after(); return obj; &#125; private void before() &#123; System.out.println(&quot;事前做好计划&quot;); &#125; private void after() &#123; System.out.println(&quot;事后回顾梳理&quot;); &#125;&#125; 这里有一个小细节，CGLib动态代理的目标对象不需要实现任何接口，它是通过动态继承目标对象实现动态代理的，客户端测试代码如下： 12345678910public class CglibTest &#123; public static void main(String[] args) &#123; try &#123; Zhangsan obj = (Zhangsan) new CustomCGlib().getInstance(Zhangsan.class); obj.learn(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 3.2 CGLib动态代理的实现原理CGLib动态代理的实现原理又是怎样的呢？可以在客户端测试代码中加上一句代码，将CGLib动态代理后的.class文件写入磁盘，然后反编译来一探究竟，代码如下： 12345//import net.sf.cglib.core.DebuggingClassWriter;//使用CGLib的代理类可以将内存中的.class文件写入本地磁盘System.setProperty(DebuggingClassWriter.DEBUG_LOCATION_PROPERTY,&quot;E://cglib_proxy_classes&quot;);Zhangsan obj = ···//··· 重新执行代码，再输出目录下会出现三个.class文件，一个是目标（被代理）类的FastClass，一个是代理类，一个是代理类的FastClass。如图： 其中，Zhangsan$$EnhancerByCGLIB$$3d23e0ea.class就是CGLib动态代理生成的代理类，继承了Zhangsan类。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.zang.cglibproxy;import java.lang.reflect.Method;import net.sf.cglib.*;public class Zhangsan$$EnhancerByCGLIB$$3d23e0ea extends Zhangsan implements Factory &#123; //··· //传入的MethodInterceptor对象 private MethodInterceptor CGLIB$CALLBACK_0; //目标类的learn方法对象 private static final Method CGLIB$learn$0$Method; //代理类的learn方法对象 private static final MethodProxy CGLIB$learn$0$Proxy; private static final Object[] CGLIB$emptyArgs; //初始化方法，其中部分代码略 static void CGLIB$STATICHOOK1() &#123; CGLIB$THREAD_CALLBACKS = new ThreadLocal(); CGLIB$emptyArgs = new Object[0]; Class var0 = Class.forName(&quot;com.zang.cglibproxy.Zhangsan$$EnhancerByCGLIB$$78b38660&quot;); Class var1; Method[] var10000 = ReflectUtils.findMethods(new String[]&#123;&quot;equals&quot;, &quot;(Ljava/lang/Object;)Z&quot;, &quot;toString&quot;, &quot;()Ljava/lang/String;&quot;, &quot;hashCode&quot;, &quot;()I&quot;, &quot;clone&quot;, &quot;()Ljava/lang/Object;&quot;&#125;, (var1 = Class.forName(&quot;java.lang.Object&quot;)).getDeclaredMethods()); //··· //初始化目标类的learn方法对象 CGLIB$learn$0$Method = ReflectUtils.findMethods(new String[]&#123;&quot;learn&quot;, &quot;()V&quot;&#125;, (var1 = Class.forName(&quot;com.zang.cglibproxy.Zhangsan&quot;)).getDeclaredMethods())[0]; //初始化代理类的learn方法对象 CGLIB$learn$0$Proxy = MethodProxy.create(var1, var0, &quot;()V&quot;, &quot;learn&quot;, &quot;CGLIB$learn$0&quot;); &#125; //这里直接调用Zhangsan#learn final void CGLIB$learn$0() &#123; super.learn(); &#125; public final void learn() &#123; MethodInterceptor var10000 = this.CGLIB$CALLBACK_0; if (var10000 == null) &#123; CGLIB$BIND_CALLBACKS(this); var10000 = this.CGLIB$CALLBACK_0; &#125; if (var10000 != null) &#123; //这里执行拦截器定义逻辑 var10000.intercept(this, CGLIB$learn$0$Method, CGLIB$emptyArgs, CGLIB$learn$0$Proxy); &#125; else &#123; super.learn(); &#125; &#125; //···&#125; 调用过程为：代理对象调用this.learn方法→调用拦截器→methodProxy.invokeSuper()→CGLIB$learn$0→被代理对象learn方法。 1234567package net.sf.cglib.proxy;import java.lang.reflect.Method;public interface MethodInterceptor extends Callback &#123; Object intercept(Object var1, Method var2, Object[] var3, MethodProxy var4) throws Throwable;&#125; 12345678910public class CustomCGlib implements MethodInterceptor &#123; //··· public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; before(); Object obj = methodProxy.invokeSuper(o,objects); after(); return obj; &#125; //···&#125; MethodInterceptor拦截器就是由MethodProxy的invokeSuper方法调用代理方法的，因此，MethodProxy类中的代码非常关键，下面分析它具体做了什么： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package net.sf.cglib.proxy;import java.lang.reflect.InvocationTargetException;import java.lang.reflect.Method;import net.sf.cglib.*;public class MethodProxy &#123; private Signature sig1; private Signature sig2; private MethodProxy.CreateInfo createInfo; private final Object initLock = new Object(); private volatile MethodProxy.FastClassInfo fastClassInfo; private void init() &#123; if (this.fastClassInfo == null) &#123; synchronized(this.initLock) &#123; if (this.fastClassInfo == null) &#123; MethodProxy.CreateInfo ci = this.createInfo; MethodProxy.FastClassInfo fci = new MethodProxy.FastClassInfo(); //创建目标类的FastClass对象(在缓存中，则取出；没在，则重新生成) fci.f1 = helper(ci, ci.c1); //创建代理类的FastClass对象 fci.f2 = helper(ci, ci.c2); //获取learn方法的索引 fci.i1 = fci.f1.getIndex(this.sig1); //获取CGLIB$learn$0方法的索引 fci.i2 = fci.f2.getIndex(this.sig2); this.fastClassInfo = fci; &#125; &#125; &#125; &#125; public Object invokeSuper(Object obj, Object[] args) throws Throwable &#123; try &#123; //初始化，创建了两个FastClass类对象 this.init(); MethodProxy.FastClassInfo fci = this.fastClassInfo; //这里将直接调用代理类的CGLIB$learn$0方法，而不是通过反射调用 //fci.f2：代理类的FastClass对象，fci.i2为CGLIB$learn$0方法对应的索引，obj为当前的代理类对象，args为learn方法的参数列表 return fci.f2.invoke(fci.i2, obj, args); &#125; catch (InvocationTargetException var4) &#123; throw var4.getTargetException(); &#125; &#125; 上面代码调用获取代理类对应的FastClass，并执行代理方法。还记得之前生成的三个.class文件吗？Zhangsan$$EnhancerByCGLIB$$78b38660$$FastClassByCGLIB$$a8f9873c.class就是代理类的FastClass，Zhangsan$$FastClassByCGLIB$$bcf7b1f4.class就是目标类的FastClass。 CGLib动态代理执行代理方法的效率之所以比JDK高，是因为CGlib采用了FastClass机制，它的原理简单来说就是：为代理类和被代理类各生成一个类，这个类会为代理类或被代理类的方法分配一个index（int类型）；这个index被当作一个入参，FastClass可以直接定位要调用的方法并直接进行调用，省去了反射调用，因此调用效率比JDK动态代理通过反射调用高（并不绝对，还需参考JDK版本及使用场景来说）。下面来反编译一个FastClass。 123456789101112131415161718192021222324252627282930313233343536public class Zhangsan$$FastClassByCGLIB$$bcf7b1f4 extends FastClass &#123; public Zhangsan$$FastClassByCGLIB$$bcf7b1f4(Class var1) &#123; super(var1); &#125; public int getIndex(Signature var1) &#123; String var10000 = var1.toString(); switch(var10000.hashCode()) &#123; case 1574139569: if (var10000.equals(&quot;learn()V&quot;)) &#123; //learn方法返回0 return 0; &#125; break; case 1826985398: if (var10000.equals(&quot;equals(Ljava/lang/Object;)Z&quot;)) &#123; //··· &#125; &#125; &#125; //根据index获取方法 public Object invoke(int var1, Object var2, Object[] var3) throws InvocationTargetException &#123; Zhangsan var10000 = (Zhangsan)var2; int var10001 = var1; try &#123; switch(var10001) &#123; case 0: //传入index为0则执行learn方法 var10000.learn(); return null; case 1: return new Boolean(var10000.equals(var3[0])); //··· FastClass并不是跟代理类一起生成的，而是在第一次执行MethodProxy的invoke或invokeSuper方法时生成的，并被放在了缓存中。 4.总结通过上面的分析，相信会对两种动态代理的实现原理有一个深入的认识，总结性比较两者的区别如下： JDK动态代理实现了被代理对象的接口，CGLib动态代理继承了被代理对象。 JDK动态代理和CGLib动态代理都在运行期生成字节码，JDK动态代理直接写Class字节码，CGLib动态代理使用ASM框架写Class字节码。CGLib动态代理实现更复杂，生成代理类比JDK动态代理效率低。 JDK动态代理调用代理方法是通过反射机制调用的，CGLib动态代理是通过FastClass机制直接调用方法的，CGLib动态代理的执行效率更高。","categories":[{"name":"技术","slug":"技术","permalink":"https://xssdpgy.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://xssdpgy.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"动态代理","slug":"动态代理","permalink":"https://xssdpgy.github.io/tags/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"},{"name":"源码分析","slug":"源码分析","permalink":"https://xssdpgy.github.io/tags/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"}]},{"title":"SpringBoot异步方法优化处理提高响应速度","slug":"SpringBoot异步方法优化处理提高响应速度","date":"2022-04-21T02:48:24.000Z","updated":"2022-09-11T15:43:16.281Z","comments":true,"path":"2022/04/21/SpringBoot异步方法优化处理提高响应速度/","link":"","permalink":"https://xssdpgy.github.io/2022/04/21/SpringBoot%E5%BC%82%E6%AD%A5%E6%96%B9%E6%B3%95%E4%BC%98%E5%8C%96%E5%A4%84%E7%90%86%E6%8F%90%E9%AB%98%E5%93%8D%E5%BA%94%E9%80%9F%E5%BA%A6/","excerpt":"1.前言日常开发中，对于串行化的任务适当解耦耗时操作和业务逻辑，在保证结果准确性的前提下，使用异步方法适当进行并行化改造，可以提高接口响应速度，提升使用体验。 如下抽象的串行化工作流程： 业务查询，首先登记记录record[cost 3s]，之后依次执行searchA[cost 1s]、searchB[cost 2s]、searchC[cost 2s]分别得到变量a、b、c，返回结果fx(a,b,c)[计算耗时可忽略不记]。代码如下：","text":"1.前言日常开发中，对于串行化的任务适当解耦耗时操作和业务逻辑，在保证结果准确性的前提下，使用异步方法适当进行并行化改造，可以提高接口响应速度，提升使用体验。 如下抽象的串行化工作流程： 业务查询，首先登记记录record[cost 3s]，之后依次执行searchA[cost 1s]、searchB[cost 2s]、searchC[cost 2s]分别得到变量a、b、c，返回结果fx(a,b,c)[计算耗时可忽略不记]。代码如下： 123456789101112131415161718192021222324252627282930import com.zang.async.service.AsyncCaseService;import lombok.extern.slf4j.Slf4j;import org.springframework.web.bind.annotation.PostMapping;import org.springframework.web.bind.annotation.RestController;import javax.annotation.Resource;import java.time.Duration;import java.time.Instant;@Slf4j@RestControllerpublic class AsyncCaseController &#123; @Resource private AsyncCaseService asyncCaseService; @PostMapping(&quot;/search/sync-test&quot;) public int syncSearch()&#123; log.info(&quot;========test start=========&quot;); Instant start = Instant.now(); asyncCaseService.record(); int a = asyncCaseService.searchA(); int b = asyncCaseService.searchB(); int c = asyncCaseService.searchC(); int result = a+b+c; Instant end = Instant.now(); log.info(&quot;========test end=========cost time is &#123;&#125; seconds&quot;, Duration.between(start,end).getSeconds()); return result; &#125; ··· 123456789101112131415161718import org.springframework.stereotype.Service;@Servicepublic class AsyncCaseServiceImpl implements AsyncCaseService&#123; @Override public int searchA() &#123; try &#123; Thread.sleep(1000);//模拟业务处理耗时 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return 1; &#125; @Override public int searchB() &#123; //其他方法类似 执行结果： 122022-04-21 13:32:47.739 INFO 22764 --- [nio-8089-exec-2] com.zang.async.web.AsyncCaseController : ========test start=========2022-04-21 13:32:55.762 INFO 22764 --- [nio-8089-exec-2] com.zang.async.web.AsyncCaseController : ========test end=========cost time is 8 seconds 经过分析，可以看到三个查询方法可以并行执行，等待都产生结果执行fx(a,b,c)，record方法执行的顺序和完成度不影响结果的返回，可以使用异步任务执行。改造逻辑抽象如下： 之后就代码实现展开阐述。 2.SpringBoot中的异步方法支持SpringBoot已经提供了异步方法支持注解，因此不需要我们自己去创建维护线程或者线程池来异步的执行方法。 主要依靠两个注解： 12@EnableAsync // 使用异步方法时需要提前开启(在启动类上或配置类上)@Async // 被async注解修饰的方法由SpringBoot默认线程池(SimpleAsyncTaskExecutor)执行 2.1 获取(有返回值)异步方法的返回值对于有返回值的异步方法，可使用java.util.concurrent.Future类及其子类来接收异步方法返回值。 1234567891011121314151617181920import org.springframework.scheduling.annotation.Async;import org.springframework.scheduling.annotation.AsyncResult;import org.springframework.stereotype.Service;import java.util.concurrent.Future;@Servicepublic class AsyncCaseServiceImpl implements AsyncCaseService&#123; @Async @Override public Future&lt;Integer&gt; searchA() &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return new AsyncResult&lt;&gt;(1); &#125; //略 无返回值异步方法的异常捕获见3.3。 2.2 异步任务并行控制接上节，在对Service中有返回值的方法进行异步改造的同时，业务处理侧需要添加并行控制，使并行的异步都返回结果才进行下一步操作： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455import com.zang.async.service.AsyncCaseService;import lombok.extern.slf4j.Slf4j;import org.springframework.web.bind.annotation.PostMapping;import org.springframework.web.bind.annotation.RestController;import javax.annotation.Resource;import java.time.Duration;import java.time.Instant;import java.util.concurrent.Future;@Slf4j@RestControllerpublic class AsyncCaseController &#123; @Resource private AsyncCaseService asyncCaseService; @PostMapping(&quot;/search/async-test&quot;) public int asyncSearch() &#123; log.info(&quot;========test start=========&quot;); Instant start = Instant.now(); asyncCaseService.record(); Future&lt;Integer&gt; searchAFuture = asyncCaseService.searchA(); Future&lt;Integer&gt; searchBFuture = asyncCaseService.searchB(); Future&lt;Integer&gt; searchCFuture = asyncCaseService.searchC(); while (true) &#123; if (searchAFuture.isDone() &amp;&amp; searchBFuture.isDone() &amp;&amp; searchCFuture.isDone()) &#123; break; &#125; if (searchAFuture.isCancelled() || searchBFuture.isCancelled() || searchCFuture.isCancelled()) &#123; log.info(&quot;async work has cancelled , break&quot;); break; &#125; try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; int a = 0, b = 0, c = 0; try &#123; a = searchAFuture.get(); b = searchBFuture.get(); c = searchCFuture.get(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; int result = a + b + c; Instant end = Instant.now(); log.info(&quot;========test end=========cost time is &#123;&#125; seconds&quot;, Duration.between(start, end).getSeconds()); return result; &#125;&#125; 结果： 122022-04-21 14:23:35.486 INFO 19912 --- [nio-8089-exec-4] com.zang.async.web.AsyncCaseController : ========test start=========2022-04-21 14:23:37.516 INFO 19912 --- [nio-8089-exec-4] com.zang.async.web.AsyncCaseController : ========test end=========cost time is 2 seconds 3.自定义线程池执行异步方法@Async使用了线程池org.springframework.core.task.SimpleAsyncTaskExecutor来执行我们的异步方法，实际开发中我们也可以自定义自己的线程池，便于对线程池进行合理配置。 3.1 自定义线程池12345678910111213141516171819202122232425262728import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.scheduling.annotation.EnableAsync;import org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;import java.util.concurrent.Executor;import java.util.concurrent.ThreadPoolExecutor;@EnableAsync@Configurationpublic class AsyncThreadPoolConfigure &#123; @Bean(&quot;asyncThreadPoolTaskExecutor&quot;) public Executor asyncThreadPoolTaskExecutor() &#123; ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(4); executor.setMaxPoolSize(4); executor.setQueueCapacity(10); executor.setKeepAliveSeconds(60); executor.setThreadNamePrefix(&quot;async-task-executor&quot;); executor.setThreadGroupName(&quot;async-task-executor-group&quot;); executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy()); // 所有任务结束后关闭线程池 //executor.setWaitForTasksToCompleteOnShutdown(true); executor.initialize(); return executor; &#125;&#125; 3.2 在@Async注解上指定执行的线程池12345@Async(&quot;asyncThreadPoolTaskExecutor&quot;)@Overridepublic Future&lt;Integer&gt; searchA() &#123; try &#123; //略 以上，自定义线程池执行异步方法即完成。 3.3 自定义线程池监控自定义的线程池配置的参数是否合理往往使人摸不着头脑，实际上，线程池执行器org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor为Spring自带的，在测试中可以创建新执行器，继承该执行器，重写submit方法，对其增加监控，从而查看线程池状态，得到合适的线程池配置。 123456789101112public class MonitorThreadPoolExecutor extends ThreadPoolTaskExecutor &#123; public void monitor()&#123; log.info(&quot;**** getActiveCount==&#123;&#125;,getPoolSize==&#123;&#125;,getLargestPoolSize==&#123;&#125;,getTaskCount==&#123;&#125;,getCompletedTaskCount==&#123;&#125;,getQueue==&#123;&#125; ***&quot;,this.getThreadPoolExecutor().getActiveCount(),this.getThreadPoolExecutor().getPoolSize(),this.getThreadPoolExecutor().getLargestPoolSize(),this.getThreadPoolExecutor().getTaskCount(),this.getThreadPoolExecutor().getCompletedTaskCount(),this.getThreadPoolExecutor().getQueue().size()); &#125; @Override public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; monitor(); return super.submit(task); &#125;&#125; 在3.1自定义线程池时创建该监控执行器即可。 3.3 无返回值异步方法的异常捕获以实现org.springframework.scheduling.annotation.AsyncConfigurer接口的getAsyncExecutor方法和getAsyncUncaughtExceptionHandler方法改造配置类。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import lombok.extern.slf4j.Slf4j;import org.springframework.aop.interceptor.AsyncUncaughtExceptionHandler;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.scheduling.annotation.AsyncConfigurer;import org.springframework.scheduling.annotation.EnableAsync;import org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;import java.lang.reflect.Method;import java.util.concurrent.Executor;import java.util.concurrent.ThreadPoolExecutor;@Slf4j@EnableAsync@Configurationpublic class AsyncThreadPoolConfigure implements AsyncConfigurer &#123; //线程池创建方法为重写 getAsyncExecutor @Bean(&quot;asyncThreadPoolTaskExecutor&quot;) @Override public Executor getAsyncExecutor() &#123; ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(4); executor.setMaxPoolSize(4); executor.setQueueCapacity(10); executor.setKeepAliveSeconds(60); executor.setThreadNamePrefix(&quot;async-task-executor&quot;); executor.setThreadGroupName(&quot;async-task-executor-group&quot;); executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy()); // 所有任务结束后关闭线程池 executor.setWaitForTasksToCompleteOnShutdown(true); executor.initialize(); return executor; &#125; @Override public AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() &#123; return new AsyncExceptionHandler(); &#125; public class AsyncExceptionHandler implements AsyncUncaughtExceptionHandler &#123; @Override public void handleUncaughtException(Throwable throwable, Method method, Object... obj) &#123; log.error(&quot;Exception message is &#123;&#125;&quot;, throwable.getMessage()); log.error(&quot;Method name is &#123;&#125; &quot;, method.getName()); for (Object param : obj) &#123; log.error(&quot;Parameter value - &#123;&#125;&quot;, param); &#125; &#125; &#125; 表现如下： 1234567891011@Async(&quot;asyncThreadPoolTaskExecutor&quot;) @Override public void record() &#123; try &#123; Thread.sleep(3000); log.info(&quot;current thread name is &#123;&#125;&quot;,Thread.currentThread().getName()); throw new RuntimeException(&quot;network not connect &quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; 控制台： 123452022-04-21 15:34:14.931 INFO 16596 --- [nio-8089-exec-1] com.zang.async.web.AsyncCaseController : ========test start=========2022-04-21 15:34:16.965 INFO 16596 --- [nio-8089-exec-1] com.zang.async.web.AsyncCaseController : ========test end=========cost time is 2 seconds2022-04-21 15:34:17.939 INFO 16596 --- [-task-executor1] c.z.async.service.AsyncCaseServiceImpl : current thread name is async-task-executor12022-04-21 15:34:17.940 ERROR 16596 --- [-task-executor1] c.z.a.c.AsyncThreadPoolConfigure : Exception message is network not connect 2022-04-21 15:34:17.941 ERROR 16596 --- [-task-executor1] c.z.a.c.AsyncThreadPoolConfigure : Method name is record 4.一些思考异步方法的集成极为方便，可以有效提高接口响应速度，但是使用过程中要注意合理的分析业务逻辑及服务器资源承载能力，不可滥用。 对于强一致性的业务，需要注意，异步方法执行失败对于前部分的已执行的非异步操作是无影响的，因此在该场景异步并不可靠； 此外，对于并发量过大的任务，异步线程池的队列缓存也较为消耗服务器资源，需要合理规划，必要时建议采用更为可靠的消息队列等中间件。","categories":[{"name":"技术","slug":"技术","permalink":"https://xssdpgy.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"异步","slug":"异步","permalink":"https://xssdpgy.github.io/tags/%E5%BC%82%E6%AD%A5/"},{"name":"优化","slug":"优化","permalink":"https://xssdpgy.github.io/tags/%E4%BC%98%E5%8C%96/"}]},{"title":"二进制方式安装k8s集群","slug":"二进制方式安装k8s集群","date":"2022-03-30T07:51:45.000Z","updated":"2022-09-11T15:43:16.282Z","comments":true,"path":"2022/03/30/二进制方式安装k8s集群/","link":"","permalink":"https://xssdpgy.github.io/2022/03/30/%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%B9%E5%BC%8F%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4/","excerpt":"使用三台服务器搭建k8s集群，集群服务器地址规划如下：","text":"使用三台服务器搭建k8s集群，集群服务器地址规划如下： IP hostname 备注 192.168.206.128 master 主节点 192.168.206.129 node1 从节点 192.168.206.130 node2 从节点 1.环境配置1.1 修改主机名master: 1hostnamectl set-hostname master node1: 1hostnamectl set-hostname node1 node2: 1hostnamectl set-hostname 1.2 关闭防火墙（all）12systemctl stop firewalldsystemctl disable firewalld 1.3 关闭selinux（all）12setenforce 0 # 临时关闭sed -i &#x27;s/SELINUX=enforcing/SELINUX=disabled/g&#x27; /etc/selinux/config # 永久关闭 1.4 关闭swap（all）123swapoff -a # 临时关闭；关闭swap主要是为了性能考虑sed -ri &#x27;s/.*swap.*/#&amp;/&#x27; /etc/fstabfree # 查看内存，swap为0则为关闭 1.5 将桥接的IPv4流量传递到iptables的链（all）1234cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOFnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1EOF 1sysctl --system 1.6 添加主机名与IP对应的关系 ( master )12345cat &gt;&gt; /etc/hosts &lt;&lt; EOF 192.168.206.128 master192.168.206.129 node1192.168.206.130 node2EOF 2.准备 cfssl 证书生成工具 ( master )cfssl 是一个开源的证书管理工具，使用 json 文件生成证书，相比 openssl 更方便使用。 找任意一台服务器操作，这里用 Master 节点。 12345678wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64chmod +x cfssl_linux-amd64 cfssljson_linux-amd64 cfssl-certinfo_linux-amd64mv cfssl_linux-amd64 /usr/local/bin/cfsslmv cfssljson_linux-amd64 /usr/local/bin/cfssljsonmv cfssl-certinfo_linux-amd64 /usr/bin/cfssl-certinfochmod +x /usr/bin/cfssl* 2.1 生成 Etcd 证书 （1）自签证书颁发机构（CA） 创建工作目录123mkdir -p ~/TLS/&#123;etcd,k8s&#125;cd TLS/etcd 2.2 自签CA1234567891011121314151617181920cat &gt; ca-config.json &lt;&lt; EOF&#123; &quot;signing&quot;: &#123; &quot;default&quot;: &#123; &quot;expiry&quot;: &quot;87600h&quot; &#125;, &quot;profiles&quot;: &#123; &quot;www&quot;: &#123; &quot;expiry&quot;: &quot;87600h&quot;, &quot;usages&quot;: [ &quot;signing&quot;, &quot;key encipherment&quot;, &quot;server auth&quot;, &quot;client auth&quot; ] &#125; &#125; &#125;&#125;EOF 12345678910111213141516cat &gt; ca-csr.json &lt;&lt; EOF&#123; &quot;CN&quot;: &quot;etcd CA&quot;, &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;L&quot;: &quot;Beijing&quot;, &quot;ST&quot;: &quot;Beijing&quot; &#125; ]&#125;EOF 2.3 生成CA证书1cfssl gencert -initca ca-csr.json | cfssljson -bare ca - 12[root@master etcd]# ls ca*pem #查看ca-key.pem ca.pem 2.4 使用自签 CA 签发 Etcd HTTPS 证书 创建证书申请文件：(修改对应的master和node的IP地址)123456789101112131415161718192021cat &gt; server-csr.json &lt;&lt; EOF&#123; &quot;CN&quot;: &quot;etcd&quot;, &quot;hosts&quot;: [ &quot;192.168.206.128&quot;, &quot;192.168.206.129&quot;, &quot;192.168.206.130&quot; ], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;L&quot;: &quot;BeiJing&quot;, &quot;ST&quot;: &quot;BeiJing&quot; &#125; ]&#125;EOF 2.5 生成SERVER证书1cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=www server-csr.json | cfssljson -bare server 12[root@master etcd]# ls server*pem #查看server-key.pem server.pem 3.部署etcd集群3.1 下载12下载地址：https://github.com/etcd-io/etcd/releases版本：3.4.14 以下在master 上操作，为简化操作，完成后将master 生成的所有文件拷贝到node1 和node2。 3.2 创建工作目录并解压二进制包123mkdir /opt/etcd/&#123;bin,cfg,ssl&#125; -ptar zxvf etcd-v3.4.14-linux-amd64.tar.gzmv etcd-v3.4.14-linux-amd64/&#123;etcd,etcdctl&#125; /opt/etcd/bin/ 3.3 创建etcd.conf12345678910111213cat &gt; /opt/etcd/cfg/etcd.conf &lt;&lt; EOF#[Member]ETCD_NAME=&quot;etcd-1&quot;ETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot;ETCD_LISTEN_PEER_URLS=&quot;https://192.168.206.128:2380&quot;ETCD_LISTEN_CLIENT_URLS=&quot;https://192.168.206.128:2379&quot;#[Clustering]ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;https://192.168.206.128:2380&quot;ETCD_ADVERTISE_CLIENT_URLS=&quot;https://192.168.206.128:2379&quot;ETCD_INITIAL_CLUSTER=&quot;etcd-1=https://192.168.206.128:2380,etcd-2=https://192.168.206.129:2380,etcd-3=https://192.168.206.130:2380&quot;ETCD_INITIAL_CLUSTER_TOKEN=&quot;etcd-cluster&quot;ETCD_INITIAL_CLUSTER_STATE=&quot;new&quot;EOF ETCD_NAME：节点名称，集群中唯一 ETCD_DATA_DIR：数据目录 ETCD_LISTEN_PEER_URLS：集群通信监听地址 ETCD_LISTEN_CLIENT_URLS：客户端访问监听地址 ETCD_INITIAL_ADVERTISE_PEER_URLS：集群通告地址 ETCD_ADVERTISE_CLIENT_URLS：客户端通告地址 ETCD_INITIAL_CLUSTER：集群节点地址 ETCD_INITIAL_CLUSTER_TOKEN：集群 Token ETCD_INITIAL_CLUSTER_STATE：加入集群的当前状态，new 是新集群，existing 表示加入 已有集群 3.4 创建etcd.service12345678910111213141516171819202122cat &gt; /usr/lib/systemd/system/etcd.service &lt;&lt; EOF[Unit]Description=Etcd ServerAfter=network.targetAfter=network-online.targetWants=network-online.target[Service]Type=notifyEnvironmentFile=/opt/etcd/cfg/etcd.confExecStart=/opt/etcd/bin/etcd \\--cert-file=/opt/etcd/ssl/server.pem \\--key-file=/opt/etcd/ssl/server-key.pem \\--peer-cert-file=/opt/etcd/ssl/server.pem \\--peer-key-file=/opt/etcd/ssl/server-key.pem \\--trusted-ca-file=/opt/etcd/ssl/ca.pem \\--peer-trusted-ca-file=/opt/etcd/ssl/ca.pem \\--logger=zapRestart=on-failureLimitNOFILE=65536[Install]WantedBy=multi-user.targetEOF 3.5 拷贝上一步生成的证书到配置路径 1cp ~/TLS/etcd/ca*pem ~/TLS/etcd/server*pem /opt/etcd/ssl/ 3.6 将master 生成的所有文件拷贝到node1 和node212345scp -r /opt/etcd/ root@192.168.206.129:/opt/scp /usr/lib/systemd/system/etcd.service root@192.168.206.129:/usr/lib/systemd/system/scp -r /opt/etcd/ root@192.168.206.130:/opt/scp /usr/lib/systemd/system/etcd.service root@192.168.206.130:/usr/lib/systemd/system/ 分别修改 etcd.conf 配置文件中的节点名称和当前服务器 IP：(node1改为 etcd-2，node2 改为 etcd-3) 3.7 启动并设置开机启动1234# 三台同时执行systemctl daemon-reloadsystemctl start etcdsystemctl enable etcd 查看状态： 1234/opt/etcd/bin/etcdctl --cacert=/opt/etcd/ssl/ca.pem --cert=/opt/etcd/ssl/server.pem --key=/opt/etcd/ssl/server-key.pem --endpoints=&quot;https://192.168.206.128:2379,https://192.168.206.129:2379,https://192.168.206.130:2379&quot; endpoint health#可视化展示/opt/etcd/bin/etcdctl --cacert=/opt/etcd/ssl/ca.pem --cert=/opt/etcd/ssl/server.pem --key=/opt/etcd/ssl/server-key.pem --endpoints=&quot;https://192.168.206.128:2379,https://192.168.206.129:2379,https://192.168.206.130:2379&quot; endpoint status --write-out=table 4.安装docker（all）4.1 下载12下载地址：https://download.docker.com/linux/static/stable/x86_64/版本：19.03.9 4.2 解压及安装12tar zxvf docker-19.03.9.tgz mv docker/* /usr/bin 4.3 systemd 管理 docker12345678910111213141516171819202122cat &gt; /usr/lib/systemd/system/docker.service &lt;&lt; EOF[Unit]Description=Docker Application Container EngineDocumentation=https://docs.docker.comAfter=network-online.target firewalld.serviceWants=network-online.target[Service]Type=notifyExecStart=/usr/bin/dockerdExecReload=/bin/kill -s HUP $MAINPIDLimitNOFILE=infinityLimitNPROC=infinityLimitCORE=infinityTimeoutStartSec=0Delegate=yesKillMode=processRestart=on-failureStartLimitBurst=3StartLimitInterval=60s[Install]WantedBy=multi-user.targetEOF 4.4 配置阿里云加速123456mkdir /etc/dockercat &gt; /etc/docker/daemon.json &lt;&lt; EOF&#123; &quot;registry-mirrors&quot;: [&quot;https://b9pmyelo.mirror.aliyuncs.com&quot;]&#125;EOF 4.5 启动并设置开机启动123systemctl daemon-reloadsystemctl start dockersystemctl enable docker 4.6 查询是否安装成功12[root@master etcd]# docker -vDocker version 19.03.9, build 9d988398e7 5.部署Master Node（master）5.1 生成 kube-apiserver 证书 自签证书颁发机构（CA）1cd TLS/k8s 1234567891011121314151617181920cat &gt; ca-config.json &lt;&lt; EOF&#123; &quot;signing&quot;: &#123; &quot;default&quot;: &#123; &quot;expiry&quot;: &quot;87600h&quot; &#125;, &quot;profiles&quot;: &#123; &quot;kubernetes&quot;: &#123; &quot;expiry&quot;: &quot;87600h&quot;, &quot;usages&quot;: [ &quot;signing&quot;, &quot;key encipherment&quot;, &quot;server auth&quot;, &quot;client auth&quot; ] &#125; &#125; &#125;&#125;EOF 123456789101112131415161718cat &gt; ca-csr.json &lt;&lt; EOF&#123; &quot;CN&quot;: &quot;kubernetes&quot;, &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;L&quot;: &quot;Beijing&quot;, &quot;ST&quot;: &quot;Beijing&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;System&quot; &#125; ]&#125;EOF 5.2 生成CA证书1cfssl gencert -initca ca-csr.json | cfssljson -bare ca - 12[root@master k8s]# ls ca*pem #查看ca-key.pem ca.pem 5.3 使用自签 CA 签发 kube-apiserver HTTPS 证书 创建证书申请文件12345678910111213141516171819202122232425262728293031cat &gt; server-csr.json &lt;&lt; EOF&#123; &quot;CN&quot;: &quot;kubernetes&quot;, &quot;hosts&quot;: [ &quot;10.0.0.1&quot;, &quot;127.0.0.1&quot;, &quot;192.168.206.128&quot;, &quot;192.168.206.129&quot;, &quot;192.168.206.130&quot;, &quot;192.168.206.131&quot;, &quot;kubernetes&quot;, &quot;kubernetes.default&quot;, &quot;kubernetes.default.svc&quot;, &quot;kubernetes.default.svc.cluster&quot;, &quot;kubernetes.default.svc.cluster.local&quot; ], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;L&quot;: &quot;BeiJing&quot;, &quot;ST&quot;: &quot;BeiJing&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;System&quot; &#125; ]&#125;EOF 注：192.168.206.131为预留出的IP。 5.4 生成SERVER证书1cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes server-csr.json | cfssljson -bare server 12[root@master k8s]# ls server*pem #查看server-key.pem server.pem 5.5 下载k8s安装包并解压12下载地址：https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.18.md#server-binaries版本：1.18.20 (压缩包名：kubernetes-server-linux-amd64.tar.gz) 12345mkdir -p /opt/kubernetes/&#123;bin,cfg,ssl,logs&#125;tar zxvf kubernetes-server-linux-amd64.tar.gzcd kubernetes/server/bincp kube-apiserver kube-scheduler kube-controller-manager /opt/kubernetes/bincp kubectl /usr/bin/ 5.6 部署kube-apiserver123456789101112131415161718192021222324252627282930cat &gt; /opt/kubernetes/cfg/kube-apiserver.conf &lt;&lt; EOFKUBE_APISERVER_OPTS=&quot;--logtostderr=false \\\\--v=2 \\\\--log-dir=/opt/kubernetes/logs \\\\--etcd-servers=https://192.168.206.128:2379,https://192.168.206.129:2379,https://192.168.206.130:2379 \\\\--bind-address=192.168.206.128 \\\\--secure-port=6443 \\\\--advertise-address=192.168.206.128 \\\\--allow-privileged=true \\\\--service-cluster-ip-range=10.0.0.0/24 \\\\--enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,ResourceQuota,NodeRestriction \\\\--authorization-mode=RBAC,Node \\\\--enable-bootstrap-token-auth=true \\\\--token-auth-file=/opt/kubernetes/cfg/token.csv \\\\--service-node-port-range=30000-32767 \\\\--kubelet-client-certificate=/opt/kubernetes/ssl/server.pem \\\\--kubelet-client-key=/opt/kubernetes/ssl/server-key.pem \\\\--tls-cert-file=/opt/kubernetes/ssl/server.pem \\\\--tls-private-key-file=/opt/kubernetes/ssl/server-key.pem \\\\--client-ca-file=/opt/kubernetes/ssl/ca.pem \\\\--service-account-key-file=/opt/kubernetes/ssl/ca-key.pem \\\\--etcd-cafile=/opt/etcd/ssl/ca.pem \\\\--etcd-certfile=/opt/etcd/ssl/server.pem \\\\--etcd-keyfile=/opt/etcd/ssl/server-key.pem \\\\--audit-log-maxage=30 \\\\--audit-log-maxbackup=3 \\\\--audit-log-maxsize=100 \\\\--audit-log-path=/opt/kubernetes/logs/k8s-audit.log&quot;EOF 上面两个\\ \\ 第一个是转义符，第二个是换行符，使用转义符是为了使用 EOF 保留换行符。 –logtostderr：启用日志 —v：日志等级 –log-dir：日志目录 –etcd-servers：etcd 集群地址 –bind-address：监听地址 –secure-port：https 安全端口 –advertise-address：集群通告地址 –allow-privileged：启用授权 –service-cluster-ip-range：Service 虚拟 IP 地址段 –enable-admission-plugins：准入控制模块 –authorization-mode：认证授权，启用 RBAC 授权和节点自管理 –enable-bootstrap-token-auth：启用 TLS bootstrap 机制 –token-auth-file：bootstrap token 文件 –service-node-port-range：Service nodeport 类型默认分配端口范围 –kubelet-client-xxx：apiserver 访问 kubelet 客户端证书 –tls-xxx-file：apiserver https 证书 –etcd-xxxfile：连接 Etcd 集群证书 –audit-log-xxx：审计日志 5.7 把生成的证书拷贝到配置文件中的路径1cp ~/TLS/k8s/ca*pem ~/TLS/k8s/server*pem /opt/kubernetes/ssl/ 5.8 创建上述配置文件中 token 文件123cat &gt; /opt/kubernetes/cfg/token.csv &lt;&lt; EOFc47ffb939f5ca36231d9e3121a252940,kubelet-bootstrap,10001,&quot;system:node-bootstrapper&quot;EOF 格式：token，用户名，UID，用户组 token 也可自行生成替换： 1head -c 16 /dev/urandom | od -An -t x | tr -d &#x27; &#x27; 5.9 systemd 管理 apiserver1234567891011cat &gt; /usr/lib/systemd/system/kube-apiserver.service &lt;&lt; EOF[Unit]Description=Kubernetes API ServerDocumentation=https://github.com/kubernetes/kubernetes[Service]EnvironmentFile=/opt/kubernetes/cfg/kube-apiserver.confExecStart=/opt/kubernetes/bin/kube-apiserver \\$KUBE_APISERVER_OPTSRestart=on-failure[Install]WantedBy=multi-user.targetEOF 启动并设置开机启动 123systemctl daemon-reloadsystemctl start kube-apiserversystemctl enable kube-apiserver 5.10 授权 kubelet-bootstrap 用户允许请求证书123kubectl create clusterrolebinding kubelet-bootstrap \\--clusterrole=system:node-bootstrapper \\--user=kubelet-bootstrap 5.11 部署 kube-controller-manager12345678910111213141516cat &gt; /opt/kubernetes/cfg/kube-controller-manager.conf &lt;&lt; EOFKUBE_CONTROLLER_MANAGER_OPTS=&quot;--logtostderr=false \\\\--v=2 \\\\--log-dir=/opt/kubernetes/logs \\\\--leader-elect=true \\\\--master=127.0.0.1:8080 \\\\--bind-address=127.0.0.1 \\\\--allocate-node-cidrs=true \\\\--cluster-cidr=10.244.0.0/16 \\\\--service-cluster-ip-range=10.0.0.0/24 \\\\--cluster-signing-cert-file=/opt/kubernetes/ssl/ca.pem \\\\--cluster-signing-key-file=/opt/kubernetes/ssl/ca-key.pem \\\\--root-ca-file=/opt/kubernetes/ssl/ca.pem \\\\--service-account-private-key-file=/opt/kubernetes/ssl/ca-key.pem \\\\--experimental-cluster-signing-duration=87600h0m0s&quot;EOF –master：通过本地非安全本地端口 8080 连接 apiserver –leader-elect：当该组件启动多个时，自动选举（HA） –cluster-signing-cert-file&#x2F;–cluster-signing-key-file：自动为 kubelet 颁发证书的 CA，与 apiserver 保持一致 5.12 systemd 管理 controller-manager1234567891011cat &gt; /usr/lib/systemd/system/kube-controller-manager.service &lt;&lt; EOF[Unit]Description=Kubernetes Controller ManagerDocumentation=https://github.com/kubernetes/kubernetes[Service]EnvironmentFile=/opt/kubernetes/cfg/kube-controller-manager.confExecStart=/opt/kubernetes/bin/kube-controller-manager \\$KUBE_CONTROLLER_MANAGER_OPTSRestart=on-failure[Install]WantedBy=multi-user.targetEOF 启动并设置开机启动 123systemctl daemon-reloadsystemctl start kube-controller-managersystemctl enable kube-controller-manager 5.13 部署 kube-scheduler12345678cat &gt; /opt/kubernetes/cfg/kube-scheduler.conf &lt;&lt; EOFKUBE_SCHEDULER_OPTS=&quot;--logtostderr=false \\--v=2 \\--log-dir=/opt/kubernetes/logs \\--leader-elect \\--master=127.0.0.1:8080 \\--bind-address=127.0.0.1&quot;EOF –master：通过本地非安全本地端口 8080 连接 apiserver –leader-elect：当该组件启动多个时，自动选举（HA） 1234567891011cat &gt; /usr/lib/systemd/system/kube-scheduler.service &lt;&lt; EOF[Unit]Description=Kubernetes SchedulerDocumentation=https://github.com/kubernetes/kubernetes[Service]EnvironmentFile=/opt/kubernetes/cfg/kube-scheduler.confExecStart=/opt/kubernetes/bin/kube-scheduler \\$KUBE_SCHEDULER_OPTSRestart=on-failure[Install]WantedBy=multi-user.targetEOF 启动并设置开机启动 123systemctl daemon-reloadsystemctl start kube-schedulersystemctl enable kube-scheduler 5.14 查看集群状态1kubectl get cs 6.部署Worker Node（两个node同步执行）6.1k8s安装包解压安装12345mkdir -p /opt/kubernetes/&#123;bin,cfg,ssl,logs&#125;tar zxvf kubernetes-server-linux-amd64.tar.gzcd kubernetes/server/bincp kubelet kube-proxy /opt/kubernetes/bincp kubectl /usr/bin/ 6.2 配置kubelet123456789101112cat &gt; /opt/kubernetes/cfg/kubelet.conf &lt;&lt; EOFKUBELET_OPTS=&quot;--logtostderr=false \\\\--v=2 \\\\--log-dir=/opt/kubernetes/logs \\\\--hostname-override=m1 \\\\--network-plugin=cni \\\\--kubeconfig=/opt/kubernetes/cfg/kubelet.kubeconfig \\\\--bootstrap-kubeconfig=/opt/kubernetes/cfg/bootstrap.kubeconfig \\\\--config=/opt/kubernetes/cfg/kubelet-config.yml \\\\--cert-dir=/opt/kubernetes/ssl \\\\--pod-infra-container-image=lizhenliang/pause-amd64:3.0&quot;EOF –hostname-override：显示名称，集群中唯一 –network-plugin：启用CNI –kubeconfig：空路径，会自动生成，后面用于连接apiserver –bootstrap-kubeconfig：首次启动向apiserver申请证书 –config：配置参数文件 –cert-dir：kubelet证书生成目录 –pod-infra-container-image：管理Pod网络容器的镜像 1234567891011121314151617181920212223242526272829303132cat &gt; /opt/kubernetes/cfg/kubelet-config.yml &lt;&lt; EOFkind: KubeletConfigurationapiVersion: kubelet.config.k8s.io/v1beta1address: 0.0.0.0port: 10250readOnlyPort: 10255cgroupDriver: cgroupfsclusterDNS:- 10.0.0.2clusterDomain: cluster.local failSwapOn: falseauthentication: anonymous: enabled: false webhook: cacheTTL: 2m0s enabled: true x509: clientCAFile: /opt/kubernetes/ssl/ca.pem authorization: mode: Webhook webhook: cacheAuthorizedTTL: 5m0s cacheUnauthorizedTTL: 30sevictionHard: imagefs.available: 15% memory.available: 100Mi nodefs.available: 10% nodefs.inodesFree: 5%maxOpenFiles: 1000000maxPods: 110EOF 6.3 将master一些配置文件拷贝到node节点上12scp -r /opt/kubernetes/ssl root@192.168.206.129:/opt/kubernetesscp -r /opt/kubernetes/ssl root@192.168.206.130:/opt/kubernetes 6.4 生成bootstrap.kubeconfig文件12KUBE_APISERVER=&quot;https://192.168.206.128:6443&quot; # apiserver IP:PORTTOKEN=&quot;c47ffb939f5ca36231d9e3121a252940&quot; # 与token.csv里保持一致 上面两个变量需要根据自己情况设置，赋到脚本对应位置执行： 12345678910111213kubectl config set-cluster kubernetes \\ --certificate-authority=/opt/kubernetes/ssl/ca.pem \\ --embed-certs=true \\ --server=$&#123;KUBE_APISERVER&#125; \\ --kubeconfig=bootstrap.kubeconfigkubectl config set-credentials &quot;kubelet-bootstrap&quot; \\ --token=$&#123;TOKEN&#125; \\ --kubeconfig=bootstrap.kubeconfigkubectl config set-context default \\ --cluster=kubernetes \\ --user=&quot;kubelet-bootstrap&quot; \\ --kubeconfig=bootstrap.kubeconfigkubectl config use-context default --kubeconfig=bootstrap.kubeconfig 1mv bootstrap.kubeconfig /opt/kubernetes/cfg 6.5 systemd管理kubelet123456789101112cat &gt; /usr/lib/systemd/system/kubelet.service &lt;&lt; EOF[Unit]Description=Kubernetes KubeletAfter=docker.service[Service]EnvironmentFile=/opt/kubernetes/cfg/kubelet.confExecStart=/opt/kubernetes/bin/kubelet \\$KUBELET_OPTSRestart=on-failureLimitNOFILE=65536[Install]WantedBy=multi-user.targetEOF 启动并设置开机启动 123systemctl daemon-reloadsystemctl start kubeletsystemctl enable kubelet 6.7 批准kubelet证书申请并加入集群（master执行）1234567891011# 查看kubelet证书请求kubectl get csrNAME AGE SIGNERNAME REQUESTOR CONDITIONnode-csr-uCEGPOIiDdlLODKts8J658HrFq9CZ--K6M4G7bjhk8A 6m3s kubernetes.io/kube-apiserver-client-kubelet kubelet-bootstrap Pendingnode-csr-***# 批准申请kubectl certificate approve node-csr-uCEGPOIiDdlLODKts8J658HrFq9CZ--K6M4G7bjhk8Akubectl certificate approve node-csr-***# 查看节点kubectl get node 由于网络插件还没有部署，节点会没有准备就绪 NotReady。 6.8 部署kube-proxy123456cat &gt; /opt/kubernetes/cfg/kube-proxy.conf &lt;&lt; EOFKUBE_PROXY_OPTS=&quot;--logtostderr=false \\\\--v=2 \\\\--log-dir=/opt/kubernetes/logs \\\\--config=/opt/kubernetes/cfg/kube-proxy-config.yml&quot;EOF 12345678910cat &gt; /opt/kubernetes/cfg/kube-proxy-config.yml &lt;&lt; EOFkind: KubeProxyConfigurationapiVersion: kubeproxy.config.k8s.io/v1alpha1bindAddress: 0.0.0.0metricsBindAddress: 0.0.0.0:10249clientConnection: kubeconfig: /opt/kubernetes/cfg/kube-proxy.kubeconfighostnameOverride: node1clusterCIDR: 10.0.0.0/24EOF hostnameOverride设置对应node机器的hostname。 6.9 生成kube-proxy.kubeconfig文件（master生成传到node）1234567891011121314151617181920212223# 切换工作目录cd TLS/k8s# 创建证书请求文件cat &gt; kube-proxy-csr.json &lt;&lt; EOF&#123; &quot;CN&quot;: &quot;system:kube-proxy&quot;, &quot;hosts&quot;: [], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;L&quot;: &quot;BeiJing&quot;, &quot;ST&quot;: &quot;BeiJing&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;System&quot; &#125; ]&#125;EOF 12# 生成证书cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kube-proxy-csr.json | cfssljson -bare kube-proxy 12[root@master k8s]# ls kube-proxy*pemkube-proxy-key.pem kube-proxy.pem 将master生成的证书传输到node 12scp /root/TLS/k8s/kube-proxy*pem root@192.168.206.129:/opt/kubernetes/sslscp /root/TLS/k8s/kube-proxy*pem root@192.168.206.130:/opt/kubernetes/ssl 6.10 生成kubeconfig文件1KUBE_APISERVER=&quot;https://192.168.206.128:6443&quot; # apiserver IP:PORT 123456789101112131415kubectl config set-cluster kubernetes \\ --certificate-authority=/opt/kubernetes/ssl/ca.pem \\ --embed-certs=true \\ --server=$&#123;KUBE_APISERVER&#125; \\ --kubeconfig=kube-proxy.kubeconfigkubectl config set-credentials kube-proxy \\ --client-certificate=/opt/kubernetes/ssl/kube-proxy.pem \\ --client-key=/opt/kubernetes/ssl/kube-proxy-key.pem \\ --embed-certs=true \\ --kubeconfig=kube-proxy.kubeconfigkubectl config set-context default \\ --cluster=kubernetes \\ --user=kube-proxy \\ --kubeconfig=kube-proxy.kubeconfigkubectl config use-context default --kubeconfig=kube-proxy.kubeconfig 6.11 systemd管理kube-proxy123456789101112cat &gt; /usr/lib/systemd/system/kube-proxy.service &lt;&lt; EOF[Unit]Description=Kubernetes ProxyAfter=network.target[Service]EnvironmentFile=/opt/kubernetes/cfg/kube-proxy.confExecStart=/opt/kubernetes/bin/kube-proxy \\$KUBE_PROXY_OPTSRestart=on-failureLimitNOFILE=65536[Install]WantedBy=multi-user.targetEOF 启动并设置开机启动： 123systemctl daemon-reloadsystemctl start kube-proxysystemctl enable kube-proxy 7.部署CNI网络下载安装 12下载地址：https://github.com/containernetworking/plugins/releases版本：v0.8.6（安装包名：cni-plugins-linux-amd64-v0.8.6.tgz） node节点操作： 12mkdir /opt/cni/bintar zxvf cni-plugins-linux-amd64-v0.8.6.tgz -C /opt/cni/bin master节点操作： 12wget --no-check-certificate https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.ymlkubectl apply -f kube-flannel.yml 参考： 【尚硅谷】Kubernetes（k8s）入门到实战教程丨全新升级完整版 k8s集群 (二进制安装方式)","categories":[{"name":"技术","slug":"技术","permalink":"https://xssdpgy.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://xssdpgy.github.io/tags/k8s/"},{"name":"安装","slug":"安装","permalink":"https://xssdpgy.github.io/tags/%E5%AE%89%E8%A3%85/"}]}],"categories":[{"name":"技术","slug":"技术","permalink":"https://xssdpgy.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://xssdpgy.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"动态代理","slug":"动态代理","permalink":"https://xssdpgy.github.io/tags/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"},{"name":"源码分析","slug":"源码分析","permalink":"https://xssdpgy.github.io/tags/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"name":"异步","slug":"异步","permalink":"https://xssdpgy.github.io/tags/%E5%BC%82%E6%AD%A5/"},{"name":"优化","slug":"优化","permalink":"https://xssdpgy.github.io/tags/%E4%BC%98%E5%8C%96/"},{"name":"k8s","slug":"k8s","permalink":"https://xssdpgy.github.io/tags/k8s/"},{"name":"安装","slug":"安装","permalink":"https://xssdpgy.github.io/tags/%E5%AE%89%E8%A3%85/"}]}